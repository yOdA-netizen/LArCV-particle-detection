{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = os.path.dirname(os.path.realpath('__file__'))\n",
    "#train_dir = home_dir+'/data/image_format_single_plane/plane-xy/*/*'\n",
    "train_dir = home_dir+'/data/image_format_small_dataset/*/*'\n",
    "\n",
    "vocab = ['electrons','protons','muons','pions','gamma']\n",
    "image_size = 64\n",
    "\n",
    "minibatch_size = 64 \n",
    "epochs = 1000\n",
    "learning_rate=0.0001\n",
    "training_size = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "  # convert the path to a list of path components and one hot them\n",
    "    parts = tf.string_split([file_path], '/')\n",
    "    label = parts.values[-2] \n",
    "    matches = tf.stack([tf.equal(label, s) for s in vocab], axis=-1)\n",
    "    onehot = tf.cast(matches, tf.float32)\n",
    "    return onehot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_img(img):\n",
    "  # convert the compressed string to a uint8 tensor\n",
    "  img = tf.image.decode_jpeg(img, channels=3)\n",
    "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "  # resize the image to the desired size.\n",
    "  img = tf.image.per_image_standardization(img)\n",
    "  return tf.image.resize(img, [image_size, image_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_path(file_path):\n",
    "  label = get_label(file_path)\n",
    "  # load the raw data from the file as a string\n",
    "  img = tf.io.read_file(file_path)\n",
    "  img = decode_img(img)\n",
    "  return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_variables():\n",
    "    with tf.variable_scope('model',reuse=tf.AUTO_REUSE):\n",
    "        #W1 is filter for first cnn layer. shape is (height,width,in_channel,out_channel)\n",
    "        W1 = tf.get_variable('W1',shape=[4,4,3,16],initializer=tf.contrib.layers.xavier_initializer())\n",
    "        W2 = tf.get_variable('W2',shape=[3,3,16,32],initializer= tf.contrib.layers.xavier_initializer())\n",
    "        W3 = tf.get_variable('W3',shape=[3,3,32,16],initializer= tf.contrib.layers.xavier_initializer())\n",
    "        parameters = {'W1':W1, 'W2':W2,'W3':W3}\n",
    "    return parameters\n",
    "\n",
    "\n",
    "def forward_prop(X,parameters):\n",
    "    '''Arguments:\n",
    "               X of shape (num_featues,batch_size)\n",
    "               parameters-- dictionary of parameters\n",
    "      Returns:\n",
    "      logits-- without calculating activation function on the last layer as the cost function doesn't need it. \n",
    "    '''\n",
    "     #Z = tf.nn.conv2d(input,Weights,strides=[1,stride_y,stride_x,1],padding='VALID')\n",
    "    #tf.nn.max_pool(x, ksize=[1, filter_height, filter_width, 1],strides = [1, stride_y, stride_x, 1],padding = padding, name = name)\n",
    "\n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    W3 = parameters['W3']\n",
    "    \n",
    "    Z1 = tf.nn.conv2d(X,W1,strides=[1,1,1,1],padding='VALID')\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    P1 = tf.nn.max_pool(A1,ksize=[1,3,3,1],strides=[1,2,2,1],padding='VALID') \n",
    "    \n",
    "    Z2 = tf.nn.conv2d(P1,W2, strides=[1,1,1,1],padding='VALID')\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    P2 = tf.nn.max_pool(A2,ksize=[1,3,3,1],strides=[1,2,2,1],padding='VALID') \n",
    "    \n",
    "    Z3 = tf.nn.conv2d(P2,W3, strides=[1,1,1,1],padding='VALID')\n",
    "    A3 = tf.nn.relu(Z3)\n",
    "    P3 = tf.nn.max_pool(A3,ksize=[1,3,3,1],strides=[1,2,2,1],padding='VALID') \n",
    "    \n",
    "    f1 = tf.contrib.layers.flatten(P3)\n",
    "    logits = tf.contrib.layers.fully_connected(f1,5,activation_fn=None)\n",
    "    return logits\n",
    "\n",
    "\n",
    "def compute_cost(Z,Y):\n",
    "    logits = tf.transpose(Z)\n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits,labels = labels))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 13507926332311175686\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 15877159185054674587\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 17437481518233674226\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 µs, sys: 0 ns, total: 6 µs\n",
      "Wall time: 11 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def model(training_dataset,learning_rate=0.00002,epochs=10):   \n",
    "    \n",
    "    with tf.variable_scope('model',reuse=tf.AUTO_REUSE):\n",
    "        with tf.device('/cpu:0'):\n",
    "            batched_training_dataset = training_dataset.batch(minibatch_size).prefetch(1)\n",
    "            iterator = tf.data.Iterator.from_structure(batched_training_dataset.output_types,batched_training_dataset.output_shapes)\n",
    "\n",
    "            training_init_op = iterator.make_initializer(batched_training_dataset)\n",
    "    #        validation_init_op = iterator.make_initializer(batched_validation_dataset)\n",
    "            next_element = iterator.get_next()\n",
    "            data = next_element     \n",
    "            X = data[0]\n",
    "            Y = data[1]\n",
    "    #        assert(X.get_shape == (minibatch_size))\n",
    "            # assert(Y.shape == (depth,minibatch_size))\n",
    "        \n",
    "        with tf.device('/gpu:0'):\n",
    "            parameters = initialize_variables()\n",
    "            logits =  forward_prop(X,parameters)\n",
    "            \n",
    "            predictions = tf.one_hot(tf.reshape(tf.argmax(logits,axis=1),shape=[-1,1]),depth=5,axis=1)\n",
    "            labels = Y\n",
    "            \n",
    "            loss = compute_cost(logits,labels)\n",
    "#            loss = compute_cost(predictions,labels)\n",
    "            \n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "            \n",
    "            \n",
    "            #labels = tf.reshape(tf.argmax(Y,axis=1), shape=[-1,1])\n",
    "            \n",
    "           # assert(predictions.shape==labels.shape)\n",
    "            print('Y shape:',Y.get_shape())\n",
    "            \n",
    "            accuracy_calculator,accuracy_updater = tf.metrics.accuracy(predictions=predictions,labels=labels,name='metric')\n",
    "            running_vars = tf.get_collection(tf.GraphKeys.LOCAL_VARIABLES,scope = 'metric')\n",
    "            running_vars_initializer = tf.variables_initializer(var_list=running_vars)\n",
    "            saver = tf.train.Saver(parameters, max_to_keep=1)\n",
    "        \n",
    "        \n",
    "        with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)) as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            sess.run(tf.local_variables_initializer())\n",
    "            num_minibatches  = int(training_size/minibatch_size)\n",
    "            for epoch in range(epochs):\n",
    "                sess.run(running_vars_initializer)\n",
    "                epoch_cost = 0                \n",
    "                sess.run(training_init_op)\n",
    "                while True:\n",
    "                    try:\n",
    "                        _, cost = sess.run([optimizer,loss])\n",
    "                        sess.run(accuracy_updater)\n",
    "                        #print('cost: {0} of epoch {1}'.format(cost,epoch))\n",
    "                        epoch_cost = epoch_cost + cost\n",
    "#                         print('predictions:',sess.run(predictions))\n",
    "#                         print('labels: ',sess.run(labels))\n",
    "#                         print('Y: ',sess.run(Y))\n",
    "#                         print('logits:',sess.run(logits))\n",
    "                    except tf.errors.OutOfRangeError:\n",
    "                        if epoch%1 == 0:\n",
    "                            accuracy = sess.run(accuracy_calculator)  \n",
    "                            epoch_cost = (epoch_cost/num_minibatches)-1\n",
    "                            print(' accuracy is {1} for epoch {0} with cost {2}'.format(epoch,accuracy,epoch_cost))\n",
    "                        break\n",
    "\n",
    "            print(\"Final accuracy \" + str(sess.run(accuracy_calculator)))\n",
    "\n",
    "            saver.save(sess, home_dir+'weights/model_parameters')\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/ops/image_ops_impl.py:1514: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From <timed exec>:6: DatasetV1.output_types (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_types(dataset)`.\n",
      "WARNING:tensorflow:From <timed exec>:6: DatasetV1.output_shapes (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_shapes(dataset)`.\n",
      "WARNING:tensorflow:From /home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py:348: Iterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_types(iterator)`.\n",
      "WARNING:tensorflow:From /home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py:349: Iterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_shapes(iterator)`.\n",
      "WARNING:tensorflow:From /home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py:351: Iterator.output_classes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_classes(iterator)`.\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/shubham/.local/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f284e357eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f284e357eb8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f284e357eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f284e357eb8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f284e57fe80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f284e57fe80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f284e57fe80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f284e57fe80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "Y shape: (?, 5)\n",
      " accuracy is 0.6765027046203613 for epoch 0 with cost 26.828038588814113\n",
      " accuracy is 0.6806011199951172 for epoch 1 with cost 26.827648992123812\n",
      " accuracy is 0.6792349815368652 for epoch 2 with cost 26.86913249803626\n",
      " accuracy is 0.6775956153869629 for epoch 3 with cost 26.94445037841797\n",
      " accuracy is 0.6792349815368652 for epoch 4 with cost 27.186153577721637\n",
      " accuracy is 0.6787796020507812 for epoch 5 with cost 27.474763123885445\n",
      " accuracy is 0.6795472502708435 for epoch 6 with cost 28.40270133640455\n",
      " accuracy is 0.6795765161514282 for epoch 7 with cost 30.28346750010615\n",
      " accuracy is 0.6791742444038391 for epoch 8 with cost 34.099786177925445\n",
      " accuracy is 0.6792349815368652 for epoch 9 with cost 41.71860968548319\n",
      " accuracy is 0.679533064365387 for epoch 10 with cost 52.41946377961532\n",
      " accuracy is 0.6797358989715576 for epoch 11 with cost 72.37005283521569\n",
      " accuracy is 0.679571270942688 for epoch 12 with cost 94.64420418117358\n",
      " accuracy is 0.679781436920166 for epoch 13 with cost 126.76394852347995\n",
      " accuracy is 0.6800000071525574 for epoch 14 with cost 164.5655046545941\n",
      " accuracy is 0.6802595853805542 for epoch 15 with cost 211.73038383152175\n",
      " accuracy is 0.6801671385765076 for epoch 16 with cost 255.01363339631456\n",
      " accuracy is 0.6799635887145996 for epoch 17 with cost 312.2845286493716\n",
      " accuracy is 0.6796663999557495 for epoch 18 with cost 364.4824802564538\n",
      " accuracy is 0.6799726486206055 for epoch 19 with cost 450.18458358101225\n",
      " accuracy is 0.6800937056541443 for epoch 20 with cost 531.1279854152514\n",
      " accuracy is 0.6799553036689758 for epoch 21 with cost 620.0223547894021\n",
      " accuracy is 0.679781436920166 for epoch 22 with cost 694.3459313434104\n",
      " accuracy is 0.679895281791687 for epoch 23 with cost 797.5617304262908\n",
      " accuracy is 0.6799562573432922 for epoch 24 with cost 930.7398150900136\n",
      " accuracy is 0.679907500743866 for epoch 25 with cost 1010.6673265540081\n",
      " accuracy is 0.6800850033760071 for epoch 26 with cost 1128.0955385954483\n",
      " accuracy is 0.6798985004425049 for epoch 27 with cost 1315.3749681555707\n",
      " accuracy is 0.679913341999054 for epoch 28 with cost 1422.4703846807065\n",
      " accuracy is 0.679836094379425 for epoch 29 with cost 1557.5656632133152\n",
      " accuracy is 0.6798343062400818 for epoch 30 with cost 1759.7115106997283\n",
      " accuracy is 0.679781436920166 for epoch 31 with cost 1855.7737134850543\n",
      " accuracy is 0.679864227771759 for epoch 32 with cost 2086.746475883152\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "list_ds = tf.data.Dataset.list_files(train_dir)\n",
    "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
    "training_dataset = list_ds.map(process_path, num_parallel_calls=5) \n",
    "model(training_dataset,learning_rate=learning_rate,epochs=epochs)\n",
    "print('works')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
