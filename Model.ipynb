{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = os.path.dirname(os.path.realpath('__file__'))\n",
    "#train_dir = home_dir+'/data/image_format_single_plane/plane-xy/*/*'\n",
    "\n",
    "train_dir = home_dir+ '/data/image_format_small_dataset/*/*'\n",
    "test_dir = home_dir + '/data/image_format_small_dataset_test/*/*'\n",
    "\n",
    "vocab = ['electrons','protons','muons','pions','gamma']\n",
    "image_size = 64\n",
    "\n",
    "minibatch_size = 64 \n",
    "epochs = 1\n",
    "learning_rate=0.00001\n",
    "training_size = 1500\n",
    "\n",
    "weight_dir = home_dir +'/weights/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "  # convert the path to a list of path components and one hot them\n",
    "    parts = tf.string_split([file_path], '/')\n",
    "    label = parts.values[-2] \n",
    "    matches = tf.stack([tf.equal(label, s) for s in vocab], axis=-1)\n",
    "    onehot = tf.cast(matches, tf.float32)\n",
    "    return onehot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_img(img):\n",
    "  # convert the compressed string to a uint8 tensor\n",
    "  img = tf.image.decode_jpeg(img, channels=3)\n",
    "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "  # resize the image to the desired size.\n",
    "  img = tf.image.per_image_standardization(img)\n",
    "  return tf.image.resize(img, [image_size, image_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_path(file_path):\n",
    "  label = get_label(file_path)\n",
    "  # load the raw data from the file as a string\n",
    "  img = tf.io.read_file(file_path)\n",
    "  img = decode_img(img)\n",
    "  return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_variables():\n",
    "    with tf.variable_scope('model',reuse=tf.AUTO_REUSE):\n",
    "        #W1 is filter for first cnn layer. shape is (height,width,in_channel,out_channel)\n",
    "        W1 = tf.get_variable('W1',shape=[4,4,3,16],initializer=tf.contrib.layers.xavier_initializer())\n",
    "        W2 = tf.get_variable('W2',shape=[3,3,16,32],initializer= tf.contrib.layers.xavier_initializer())\n",
    "        W3 = tf.get_variable('W3',shape=[3,3,32,16],initializer= tf.contrib.layers.xavier_initializer())\n",
    "        parameters = {'W1':W1, 'W2':W2,'W3':W3}\n",
    "    return parameters\n",
    "\n",
    "\n",
    "def forward_prop(X,parameters, is_train=True):\n",
    "    '''Arguments:\n",
    "               X of shape (num_featues,batch_size)\n",
    "  tf.reset_default_graph()              parameters-- dictionary of parameters\n",
    "      Returns:\n",
    "      logits-- without calculating activation function on the last layer as the cost function doesn't need it. \n",
    "    '''\n",
    "     #Z = tf.nn.conv2d(input,Weights,strides=[1,stride_y,stride_x,1],padding='VALID')\n",
    "    #tf.nn.max_pool(x, ksize=[1, filter_height, filter_width, 1],strides = [1, stride_y, stride_x, 1],padding = padding, name = name)\n",
    "    if is_train:\n",
    "        W1 = parameters['W1']\n",
    "        W2 = parameters['W2']\n",
    "        W3 = parameters['W3']\n",
    "    else:\n",
    "        W1 = parameters[0]\n",
    "        W2 = parameters[1]\n",
    "        W3 = parameters[2]\n",
    "\n",
    "\n",
    "    Z1 = tf.nn.conv2d(X,W1,strides=[1,1,1,1],padding='VALID')\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    P1 = tf.nn.max_pool(A1,ksize=[1,3,3,1],strides=[1,2,2,1],padding='VALID') \n",
    "\n",
    "    Z2 = tf.nn.conv2d(P1,W2, strides=[1,1,1,1],padding='VALID')\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    P2 = tf.nn.max_pool(A2,ksize=[1,3,3,1],strides=[1,2,2,1],padding='VALID') \n",
    "\n",
    "    Z3 = tf.nn.conv2d(P2,W3, strides=[1,1,1,1],padding='VALID')\n",
    "    A3 = tf.nn.relu(Z3)\n",
    "    P3 = tf.nn.max_pool(A3,ksize=[1,3,3,1],strides=[1,2,2,1],padding='VALID') \n",
    "\n",
    "    f1 = tf.contrib.layers.flatten(P3)\n",
    "    logits = tf.contrib.layers.fully_connected(f1,5,activation_fn=None)\n",
    "    return logits\n",
    "\n",
    "\n",
    "def compute_cost(Z,Y):\n",
    "    logits = tf.transpose(Z)\n",
    "    labels = tf.transpose(Y)\n",
    "\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits,labels = labels))\n",
    "   #if epoch%10 == 0: cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,labels=labels))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10186698254329189561\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 10190139513790566549\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 17755132303208719022\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 1 µs, total: 5 µs\n",
      "Wall time: 7.39 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def build_model(train_dir,learning_rate=0.00002,epochs=10,is_train=True):   \n",
    "    \n",
    "    if(is_train):\n",
    "    \n",
    "        with tf.variable_scope('model',reuse=tf.AUTO_REUSE):\n",
    "            with tf.device('/cpu:0'):\n",
    "                list_ds = tf.data.Dataset.list_files(train_dir)\n",
    "    # Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
    "                training_dataset = list_ds.map(process_path, num_parallel_calls=8)\n",
    "\n",
    "                batched_training_dataset = training_dataset.shuffle(buffer_size=300).batch(minibatch_size).prefetch(1)\n",
    "                iterator = tf.data.Iterator.from_structure(batched_training_dataset.output_types,batched_training_dataset.output_shapes)\n",
    "\n",
    "                training_init_op = iterator.make_initializer(batched_training_dataset)\n",
    "        #        validation_init_op = iterator.make_initializer(batched_validation_dataset)\n",
    "                next_element = iterator.get_next()\n",
    "                data = next_element     \n",
    "                X = data[0]\n",
    "                Y = data[1]\n",
    "        #        assert(X.get_shape == (minibatch_size))\n",
    "                # assert(Y.shape == (depth,minibatch_size))\n",
    "\n",
    "            with tf.device('/gpu:0'):\n",
    "                parameters = initialize_variables()\n",
    "                logits =  forward_prop(X,parameters)\n",
    "\n",
    "                predictions = tf.one_hot(tf.argmax(logits,axis=1),depth=5,axis=1)\n",
    "                labels = tf.cast(Y,dtype=tf.int64)\n",
    "\n",
    "                loss = compute_cost(logits,labels)\n",
    "    #            loss = compute_cost(predictions,labels)\n",
    "\n",
    "                optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "\n",
    "                #labels = tf.reshape(tf.argmax(Y,axis=1), shape=[-1,1])\n",
    "\n",
    "               # assert(predictions.shape==labels.shape)\n",
    "                print('predictions shape:',predictions.get_shape())\n",
    "                print('labels shape:',labels.get_shape())\n",
    "                print('logits shape:',logits.get_shape())\n",
    "                \n",
    "                equality = tf.equal(predictions, Y)\n",
    "                accuracy_2 = tf.reduce_mean(tf.cast(equality, tf.float32))\n",
    "\n",
    "                accuracy_calculator,accuracy_updater = tf.metrics.accuracy(predictions=predictions,labels=labels,name='metric')\n",
    "                running_vars = tf.get_collection(tf.GraphKeys.LOCAL_VARIABLES,scope = 'model')\n",
    "                running_vars_initializer = tf.variables_initializer(var_list=running_vars)\n",
    "                saver = tf.train.Saver(parameters, max_to_keep=1)\n",
    "                 \n",
    "               \n",
    "\n",
    "            with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)) as sess:\n",
    "                sess.run(tf.global_variables_initializer())\n",
    "                sess.run(tf.local_variables_initializer())\n",
    "                num_minibatches  = int(training_size/minibatch_size)-1\n",
    "                writer = tf.summary.FileWriter(home_dir+'/graphs', sess.graph)\n",
    "                for epoch in range(epochs):\n",
    "                    sess.run(running_vars_initializer)\n",
    "                    epoch_cost = 0                \n",
    "                    sess.run(training_init_op)\n",
    "                    while True:\n",
    "                        try:\n",
    "                            _, cost = sess.run([optimizer,loss])\n",
    "                            sess.run(accuracy_updater)\n",
    "    #                         if epoch%10 == 0:\n",
    "    #                             print('cost: {0} of epoch {1}'.format(cost,epoch))\n",
    "                            epoch_cost = epoch_cost + cost\n",
    "    #                         print('predictions:',sess.run(predictions))\n",
    "    #                         print('labels: ',sess.run(labels))\n",
    "    #                         print('Y: ',sess.run(Y))\n",
    "    #                         print('logits:',sess.run(logits))\n",
    "                            acc_2 = sess.run(accuracy_2)\n",
    "                        except tf.errors.OutOfRangeError:\n",
    "                            if epoch%1 == 0:\n",
    "                                accuracy = sess.run(accuracy_calculator)  \n",
    "                                epoch_cost = (epoch_cost/num_minibatches)\n",
    "                                \n",
    "#                                 y_pred = sess.run(predictions)\n",
    "#                                 y_true = sess.run(labels)\n",
    "#                                 sk_accuracy = sklearn.metrics.accuracy_score(y_true[0], y_pred[0])\n",
    "                                print(' accuracy is {1} for epoch {0} with cost {2} with accuracy_2: {3} '.format(epoch,accuracy,epoch_cost,acc_2))\n",
    "                            break\n",
    "\n",
    "                print(\"Final accuracy \" + str(sess.run(accuracy_calculator)))\n",
    "\n",
    "                saver.save(sess, home_dir+'/weights/model_parameters')\n",
    "                return saver\n",
    "      \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7feb8c1e2e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7feb8c1e2e10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7feb8c1e2e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7feb8c1e2e10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7feb8c1e2828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7feb8c1e2828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7feb8c1e2828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7feb8c1e2828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "predictions shape: (?, 5)\n",
      "labels shape: (?, 5)\n",
      "logits shape: (?, 5)\n",
      " accuracy is 0.6820312738418579 for epoch 0 with cost 19.435639468106356 with accuracy_2: 0.6714285612106323 \n",
      "Final accuracy 0.6820313\n",
      "works\n",
      "CPU times: user 11.2 s, sys: 424 ms, total: 11.6 s\n",
      "Wall time: 2.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# list_ds = tf.data.Dataset.list_files(train_dir)\n",
    "# # Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
    "# training_dataset = list_ds.map(process_path, num_parallel_calls=5) \n",
    "model = build_model(train_dir,learning_rate=learning_rate,epochs=epochs)\n",
    "print('works')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/list_files/file_pattern',\n",
       " 'model/list_files/MatchingFiles',\n",
       " 'model/list_files/Shape',\n",
       " 'model/list_files/strided_slice/stack',\n",
       " 'model/list_files/strided_slice/stack_1',\n",
       " 'model/list_files/strided_slice/stack_2',\n",
       " 'model/list_files/strided_slice',\n",
       " 'model/list_files/match_not_empty/y',\n",
       " 'model/list_files/match_not_empty',\n",
       " 'model/list_files/Const',\n",
       " 'model/list_files/ReduceJoin',\n",
       " 'model/list_files/message/x',\n",
       " 'model/list_files/message',\n",
       " 'model/list_files/assert_not_empty/Assert',\n",
       " 'model/list_files/Identity',\n",
       " 'model/list_files/TensorSliceDataset',\n",
       " 'model/list_files/Shape_1',\n",
       " 'model/list_files/strided_slice_1/stack',\n",
       " 'model/list_files/strided_slice_1/stack_1',\n",
       " 'model/list_files/strided_slice_1/stack_2',\n",
       " 'model/list_files/strided_slice_1',\n",
       " 'model/list_files/Maximum/y',\n",
       " 'model/list_files/Maximum',\n",
       " 'model/list_files/seed',\n",
       " 'model/list_files/seed2',\n",
       " 'model/list_files/ShuffleDataset',\n",
       " 'model/num_parallel_calls',\n",
       " 'model/ParallelMapDataset',\n",
       " 'model/buffer_size',\n",
       " 'model/seed',\n",
       " 'model/seed2',\n",
       " 'model/ShuffleDataset',\n",
       " 'model/batch_size',\n",
       " 'model/drop_remainder',\n",
       " 'model/BatchDatasetV2',\n",
       " 'model/buffer_size_1',\n",
       " 'model/PrefetchDataset',\n",
       " 'model/IteratorV2',\n",
       " 'model/IteratorToStringHandle',\n",
       " 'model/make_initializer',\n",
       " 'model/IteratorGetNext',\n",
       " 'model/model/W1/Initializer/random_uniform/shape',\n",
       " 'model/model/W1/Initializer/random_uniform/min',\n",
       " 'model/model/W1/Initializer/random_uniform/max',\n",
       " 'model/model/W1/Initializer/random_uniform/RandomUniform',\n",
       " 'model/model/W1/Initializer/random_uniform/sub',\n",
       " 'model/model/W1/Initializer/random_uniform/mul',\n",
       " 'model/model/W1/Initializer/random_uniform',\n",
       " 'model/model/W1',\n",
       " 'model/model/W1/Assign',\n",
       " 'model/model/W1/read',\n",
       " 'model/model/W2/Initializer/random_uniform/shape',\n",
       " 'model/model/W2/Initializer/random_uniform/min',\n",
       " 'model/model/W2/Initializer/random_uniform/max',\n",
       " 'model/model/W2/Initializer/random_uniform/RandomUniform',\n",
       " 'model/model/W2/Initializer/random_uniform/sub',\n",
       " 'model/model/W2/Initializer/random_uniform/mul',\n",
       " 'model/model/W2/Initializer/random_uniform',\n",
       " 'model/model/W2',\n",
       " 'model/model/W2/Assign',\n",
       " 'model/model/W2/read',\n",
       " 'model/model/W3/Initializer/random_uniform/shape',\n",
       " 'model/model/W3/Initializer/random_uniform/min',\n",
       " 'model/model/W3/Initializer/random_uniform/max',\n",
       " 'model/model/W3/Initializer/random_uniform/RandomUniform',\n",
       " 'model/model/W3/Initializer/random_uniform/sub',\n",
       " 'model/model/W3/Initializer/random_uniform/mul',\n",
       " 'model/model/W3/Initializer/random_uniform',\n",
       " 'model/model/W3',\n",
       " 'model/model/W3/Assign',\n",
       " 'model/model/W3/read',\n",
       " 'model/Conv2D',\n",
       " 'model/Relu',\n",
       " 'model/MaxPool',\n",
       " 'model/Conv2D_1',\n",
       " 'model/Relu_1',\n",
       " 'model/MaxPool_1',\n",
       " 'model/Conv2D_2',\n",
       " 'model/Relu_2',\n",
       " 'model/MaxPool_2',\n",
       " 'model/Flatten/flatten/Shape',\n",
       " 'model/Flatten/flatten/strided_slice/stack',\n",
       " 'model/Flatten/flatten/strided_slice/stack_1',\n",
       " 'model/Flatten/flatten/strided_slice/stack_2',\n",
       " 'model/Flatten/flatten/strided_slice',\n",
       " 'model/Flatten/flatten/Reshape/shape/1',\n",
       " 'model/Flatten/flatten/Reshape/shape',\n",
       " 'model/Flatten/flatten/Reshape',\n",
       " 'model/fully_connected/weights/Initializer/random_uniform/shape',\n",
       " 'model/fully_connected/weights/Initializer/random_uniform/min',\n",
       " 'model/fully_connected/weights/Initializer/random_uniform/max',\n",
       " 'model/fully_connected/weights/Initializer/random_uniform/RandomUniform',\n",
       " 'model/fully_connected/weights/Initializer/random_uniform/sub',\n",
       " 'model/fully_connected/weights/Initializer/random_uniform/mul',\n",
       " 'model/fully_connected/weights/Initializer/random_uniform',\n",
       " 'model/fully_connected/weights',\n",
       " 'model/fully_connected/weights/Assign',\n",
       " 'model/fully_connected/weights/read',\n",
       " 'model/fully_connected/biases/Initializer/zeros',\n",
       " 'model/fully_connected/biases',\n",
       " 'model/fully_connected/biases/Assign',\n",
       " 'model/fully_connected/biases/read',\n",
       " 'model/fully_connected/MatMul',\n",
       " 'model/fully_connected/BiasAdd',\n",
       " 'model/ArgMax/dimension',\n",
       " 'model/ArgMax',\n",
       " 'model/one_hot/on_value',\n",
       " 'model/one_hot/off_value',\n",
       " 'model/one_hot/depth',\n",
       " 'model/one_hot',\n",
       " 'model/Cast',\n",
       " 'model/transpose/perm',\n",
       " 'model/transpose',\n",
       " 'model/transpose_1/perm',\n",
       " 'model/transpose_1',\n",
       " 'model/softmax_cross_entropy_with_logits/Cast',\n",
       " 'model/softmax_cross_entropy_with_logits/Rank',\n",
       " 'model/softmax_cross_entropy_with_logits/Shape',\n",
       " 'model/softmax_cross_entropy_with_logits/Rank_1',\n",
       " 'model/softmax_cross_entropy_with_logits/Shape_1',\n",
       " 'model/softmax_cross_entropy_with_logits/Sub/y',\n",
       " 'model/softmax_cross_entropy_with_logits/Sub',\n",
       " 'model/softmax_cross_entropy_with_logits/Slice/begin',\n",
       " 'model/softmax_cross_entropy_with_logits/Slice/size',\n",
       " 'model/softmax_cross_entropy_with_logits/Slice',\n",
       " 'model/softmax_cross_entropy_with_logits/concat/values_0',\n",
       " 'model/softmax_cross_entropy_with_logits/concat/axis',\n",
       " 'model/softmax_cross_entropy_with_logits/concat',\n",
       " 'model/softmax_cross_entropy_with_logits/Reshape',\n",
       " 'model/softmax_cross_entropy_with_logits/Rank_2',\n",
       " 'model/softmax_cross_entropy_with_logits/Shape_2',\n",
       " 'model/softmax_cross_entropy_with_logits/Sub_1/y',\n",
       " 'model/softmax_cross_entropy_with_logits/Sub_1',\n",
       " 'model/softmax_cross_entropy_with_logits/Slice_1/begin',\n",
       " 'model/softmax_cross_entropy_with_logits/Slice_1/size',\n",
       " 'model/softmax_cross_entropy_with_logits/Slice_1',\n",
       " 'model/softmax_cross_entropy_with_logits/concat_1/values_0',\n",
       " 'model/softmax_cross_entropy_with_logits/concat_1/axis',\n",
       " 'model/softmax_cross_entropy_with_logits/concat_1',\n",
       " 'model/softmax_cross_entropy_with_logits/Reshape_1',\n",
       " 'model/softmax_cross_entropy_with_logits',\n",
       " 'model/softmax_cross_entropy_with_logits/Sub_2/y',\n",
       " 'model/softmax_cross_entropy_with_logits/Sub_2',\n",
       " 'model/softmax_cross_entropy_with_logits/Slice_2/begin',\n",
       " 'model/softmax_cross_entropy_with_logits/Slice_2/size',\n",
       " 'model/softmax_cross_entropy_with_logits/Slice_2',\n",
       " 'model/softmax_cross_entropy_with_logits/Reshape_2',\n",
       " 'model/Const',\n",
       " 'model/Mean',\n",
       " 'model/gradients/Shape',\n",
       " 'model/gradients/grad_ys_0',\n",
       " 'model/gradients/Fill',\n",
       " 'model/gradients/model/Mean_grad/Reshape/shape',\n",
       " 'model/gradients/model/Mean_grad/Reshape',\n",
       " 'model/gradients/model/Mean_grad/Const',\n",
       " 'model/gradients/model/Mean_grad/Tile',\n",
       " 'model/gradients/model/Mean_grad/Const_1',\n",
       " 'model/gradients/model/Mean_grad/truediv',\n",
       " 'model/gradients/model/softmax_cross_entropy_with_logits/Reshape_2_grad/Shape',\n",
       " 'model/gradients/model/softmax_cross_entropy_with_logits/Reshape_2_grad/Reshape',\n",
       " 'model/gradients/zeros_like',\n",
       " 'model/gradients/model/softmax_cross_entropy_with_logits_grad/ExpandDims/dim',\n",
       " 'model/gradients/model/softmax_cross_entropy_with_logits_grad/ExpandDims',\n",
       " 'model/gradients/model/softmax_cross_entropy_with_logits_grad/mul',\n",
       " 'model/gradients/model/softmax_cross_entropy_with_logits_grad/LogSoftmax',\n",
       " 'model/gradients/model/softmax_cross_entropy_with_logits_grad/Neg',\n",
       " 'model/gradients/model/softmax_cross_entropy_with_logits_grad/ExpandDims_1/dim',\n",
       " 'model/gradients/model/softmax_cross_entropy_with_logits_grad/ExpandDims_1',\n",
       " 'model/gradients/model/softmax_cross_entropy_with_logits_grad/mul_1',\n",
       " 'model/gradients/model/softmax_cross_entropy_with_logits_grad/tuple/group_deps',\n",
       " 'model/gradients/model/softmax_cross_entropy_with_logits_grad/tuple/control_dependency',\n",
       " 'model/gradients/model/softmax_cross_entropy_with_logits_grad/tuple/control_dependency_1',\n",
       " 'model/gradients/model/softmax_cross_entropy_with_logits/Reshape_grad/Shape',\n",
       " 'model/gradients/model/softmax_cross_entropy_with_logits/Reshape_grad/Reshape',\n",
       " 'model/gradients/model/transpose_grad/InvertPermutation',\n",
       " 'model/gradients/model/transpose_grad/transpose',\n",
       " 'model/gradients/model/fully_connected/BiasAdd_grad/BiasAddGrad',\n",
       " 'model/gradients/model/fully_connected/BiasAdd_grad/tuple/group_deps',\n",
       " 'model/gradients/model/fully_connected/BiasAdd_grad/tuple/control_dependency',\n",
       " 'model/gradients/model/fully_connected/BiasAdd_grad/tuple/control_dependency_1',\n",
       " 'model/gradients/model/fully_connected/MatMul_grad/MatMul',\n",
       " 'model/gradients/model/fully_connected/MatMul_grad/MatMul_1',\n",
       " 'model/gradients/model/fully_connected/MatMul_grad/tuple/group_deps',\n",
       " 'model/gradients/model/fully_connected/MatMul_grad/tuple/control_dependency',\n",
       " 'model/gradients/model/fully_connected/MatMul_grad/tuple/control_dependency_1',\n",
       " 'model/gradients/model/Flatten/flatten/Reshape_grad/Shape',\n",
       " 'model/gradients/model/Flatten/flatten/Reshape_grad/Reshape',\n",
       " 'model/gradients/model/MaxPool_2_grad/MaxPoolGrad',\n",
       " 'model/gradients/model/Relu_2_grad/ReluGrad',\n",
       " 'model/gradients/model/Conv2D_2_grad/ShapeN',\n",
       " 'model/gradients/model/Conv2D_2_grad/Conv2DBackpropInput',\n",
       " 'model/gradients/model/Conv2D_2_grad/Conv2DBackpropFilter',\n",
       " 'model/gradients/model/Conv2D_2_grad/tuple/group_deps',\n",
       " 'model/gradients/model/Conv2D_2_grad/tuple/control_dependency',\n",
       " 'model/gradients/model/Conv2D_2_grad/tuple/control_dependency_1',\n",
       " 'model/gradients/model/MaxPool_1_grad/MaxPoolGrad',\n",
       " 'model/gradients/model/Relu_1_grad/ReluGrad',\n",
       " 'model/gradients/model/Conv2D_1_grad/ShapeN',\n",
       " 'model/gradients/model/Conv2D_1_grad/Conv2DBackpropInput',\n",
       " 'model/gradients/model/Conv2D_1_grad/Conv2DBackpropFilter',\n",
       " 'model/gradients/model/Conv2D_1_grad/tuple/group_deps',\n",
       " 'model/gradients/model/Conv2D_1_grad/tuple/control_dependency',\n",
       " 'model/gradients/model/Conv2D_1_grad/tuple/control_dependency_1',\n",
       " 'model/gradients/model/MaxPool_grad/MaxPoolGrad',\n",
       " 'model/gradients/model/Relu_grad/ReluGrad',\n",
       " 'model/gradients/model/Conv2D_grad/ShapeN',\n",
       " 'model/gradients/model/Conv2D_grad/Conv2DBackpropInput',\n",
       " 'model/gradients/model/Conv2D_grad/Conv2DBackpropFilter',\n",
       " 'model/gradients/model/Conv2D_grad/tuple/group_deps',\n",
       " 'model/gradients/model/Conv2D_grad/tuple/control_dependency',\n",
       " 'model/gradients/model/Conv2D_grad/tuple/control_dependency_1',\n",
       " 'model/beta1_power/initial_value',\n",
       " 'model/beta1_power',\n",
       " 'model/beta1_power/Assign',\n",
       " 'model/beta1_power/read',\n",
       " 'model/beta2_power/initial_value',\n",
       " 'model/beta2_power',\n",
       " 'model/beta2_power/Assign',\n",
       " 'model/beta2_power/read',\n",
       " 'model/model/model/W1/Adam/Initializer/zeros',\n",
       " 'model/model/model/W1/Adam',\n",
       " 'model/model/model/W1/Adam/Assign',\n",
       " 'model/model/model/W1/Adam/read',\n",
       " 'model/model/model/W1/Adam_1/Initializer/zeros',\n",
       " 'model/model/model/W1/Adam_1',\n",
       " 'model/model/model/W1/Adam_1/Assign',\n",
       " 'model/model/model/W1/Adam_1/read',\n",
       " 'model/model/model/W2/Adam/Initializer/zeros/shape_as_tensor',\n",
       " 'model/model/model/W2/Adam/Initializer/zeros/Const',\n",
       " 'model/model/model/W2/Adam/Initializer/zeros',\n",
       " 'model/model/model/W2/Adam',\n",
       " 'model/model/model/W2/Adam/Assign',\n",
       " 'model/model/model/W2/Adam/read',\n",
       " 'model/model/model/W2/Adam_1/Initializer/zeros/shape_as_tensor',\n",
       " 'model/model/model/W2/Adam_1/Initializer/zeros/Const',\n",
       " 'model/model/model/W2/Adam_1/Initializer/zeros',\n",
       " 'model/model/model/W2/Adam_1',\n",
       " 'model/model/model/W2/Adam_1/Assign',\n",
       " 'model/model/model/W2/Adam_1/read',\n",
       " 'model/model/model/W3/Adam/Initializer/zeros/shape_as_tensor',\n",
       " 'model/model/model/W3/Adam/Initializer/zeros/Const',\n",
       " 'model/model/model/W3/Adam/Initializer/zeros',\n",
       " 'model/model/model/W3/Adam',\n",
       " 'model/model/model/W3/Adam/Assign',\n",
       " 'model/model/model/W3/Adam/read',\n",
       " 'model/model/model/W3/Adam_1/Initializer/zeros/shape_as_tensor',\n",
       " 'model/model/model/W3/Adam_1/Initializer/zeros/Const',\n",
       " 'model/model/model/W3/Adam_1/Initializer/zeros',\n",
       " 'model/model/model/W3/Adam_1',\n",
       " 'model/model/model/W3/Adam_1/Assign',\n",
       " 'model/model/model/W3/Adam_1/read',\n",
       " 'model/model/fully_connected/weights/Adam/Initializer/zeros/shape_as_tensor',\n",
       " 'model/model/fully_connected/weights/Adam/Initializer/zeros/Const',\n",
       " 'model/model/fully_connected/weights/Adam/Initializer/zeros',\n",
       " 'model/model/fully_connected/weights/Adam',\n",
       " 'model/model/fully_connected/weights/Adam/Assign',\n",
       " 'model/model/fully_connected/weights/Adam/read',\n",
       " 'model/model/fully_connected/weights/Adam_1/Initializer/zeros/shape_as_tensor',\n",
       " 'model/model/fully_connected/weights/Adam_1/Initializer/zeros/Const',\n",
       " 'model/model/fully_connected/weights/Adam_1/Initializer/zeros',\n",
       " 'model/model/fully_connected/weights/Adam_1',\n",
       " 'model/model/fully_connected/weights/Adam_1/Assign',\n",
       " 'model/model/fully_connected/weights/Adam_1/read',\n",
       " 'model/model/fully_connected/biases/Adam/Initializer/zeros',\n",
       " 'model/model/fully_connected/biases/Adam',\n",
       " 'model/model/fully_connected/biases/Adam/Assign',\n",
       " 'model/model/fully_connected/biases/Adam/read',\n",
       " 'model/model/fully_connected/biases/Adam_1/Initializer/zeros',\n",
       " 'model/model/fully_connected/biases/Adam_1',\n",
       " 'model/model/fully_connected/biases/Adam_1/Assign',\n",
       " 'model/model/fully_connected/biases/Adam_1/read',\n",
       " 'model/Adam/learning_rate',\n",
       " 'model/Adam/beta1',\n",
       " 'model/Adam/beta2',\n",
       " 'model/Adam/epsilon',\n",
       " 'model/Adam/update_model/model/W1/ApplyAdam',\n",
       " 'model/Adam/update_model/model/W2/ApplyAdam',\n",
       " 'model/Adam/update_model/model/W3/ApplyAdam',\n",
       " 'model/Adam/update_model/fully_connected/weights/ApplyAdam',\n",
       " 'model/Adam/update_model/fully_connected/biases/ApplyAdam',\n",
       " 'model/Adam/mul',\n",
       " 'model/Adam/Assign',\n",
       " 'model/Adam/mul_1',\n",
       " 'model/Adam/Assign_1',\n",
       " 'model/Adam',\n",
       " 'model/Equal',\n",
       " 'model/Cast_1',\n",
       " 'model/Const_1',\n",
       " 'model/Mean_1',\n",
       " 'model/Cast_2',\n",
       " 'model/Equal_1',\n",
       " 'model/Cast_3',\n",
       " 'model/metric/total/Initializer/zeros',\n",
       " 'model/metric/total',\n",
       " 'model/metric/total/Assign',\n",
       " 'model/metric/total/read',\n",
       " 'model/metric/count/Initializer/zeros',\n",
       " 'model/metric/count',\n",
       " 'model/metric/count/Assign',\n",
       " 'model/metric/count/read',\n",
       " 'model/metric/Size',\n",
       " 'model/metric/Cast',\n",
       " 'model/metric/Const',\n",
       " 'model/metric/Sum',\n",
       " 'model/metric/AssignAdd',\n",
       " 'model/metric/AssignAdd_1',\n",
       " 'model/metric/Maximum/y',\n",
       " 'model/metric/Maximum',\n",
       " 'model/metric/value',\n",
       " 'model/metric/Maximum_1/y',\n",
       " 'model/metric/Maximum_1',\n",
       " 'model/metric/update_op',\n",
       " 'model/init',\n",
       " 'model/save/filename/input',\n",
       " 'model/save/filename',\n",
       " 'model/save/Const',\n",
       " 'model/save/SaveV2/tensor_names',\n",
       " 'model/save/SaveV2/shape_and_slices',\n",
       " 'model/save/SaveV2',\n",
       " 'model/save/control_dependency',\n",
       " 'model/save/RestoreV2/tensor_names',\n",
       " 'model/save/RestoreV2/shape_and_slices',\n",
       " 'model/save/RestoreV2',\n",
       " 'model/save/Assign',\n",
       " 'model/save/Assign_1',\n",
       " 'model/save/Assign_2',\n",
       " 'model/save/restore_all',\n",
       " 'model/init_1',\n",
       " 'model/init_2']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[n.name for n in tf.get_default_graph().as_graph_def().node]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(test_dir):\n",
    "   # tf.reset_default_graph()\n",
    "    list_ds = tf.data.Dataset.list_files(test_dir)\n",
    "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
    "    test_dataset = list_ds.map(process_path, num_parallel_calls=8)\n",
    "#    iterator = test_dataset.make_one_shot_iterator()\n",
    "    with tf.Session() as sess:\n",
    "    #  data = iterator.get_next()\n",
    "      for data in test_dataset:\n",
    "          X = data[0]\n",
    "          Y = data[1]\n",
    "          parameters = sess.run(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES))\n",
    "        #  tf.reset_default_graph()\n",
    "          print(parameters)\n",
    "          logits = forward_prop(X,parameters,is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot assign a device for operation model/model/W1/Initializer/random_uniform/RandomUniform: Could not satisfy explicit device specification '' because the node node model/model/W1/Initializer/random_uniform/RandomUniform (defined at <ipython-input-6-43fb2aff1ac7>:4) placed on device Device assignments active during op 'model/model/W1/Initializer/random_uniform/RandomUniform' creation:\n  with tf.device(None): </home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py:1696>\n  with tf.device(/gpu:0): <<timed exec>:23>  was colocated with a group of nodes that required incompatible device '/device:GPU:0'. All available devices [/job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_GPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0]. \nColocation Debug Info:\nColocation group had the following types and supported devices: \nRoot Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\nAssign: CPU \nIdentity: CPU XLA_CPU XLA_GPU \nVariableV2: CPU \nMul: CPU XLA_CPU XLA_GPU \nAdd: CPU XLA_CPU XLA_GPU \nSub: CPU XLA_CPU XLA_GPU \nRandomUniform: CPU XLA_CPU XLA_GPU \nApplyAdam: CPU \nConst: CPU XLA_CPU XLA_GPU \n\nColocation members, user-requested devices, and framework assigned devices, if any:\n  model/model/W1/Initializer/random_uniform/shape (Const) \n  model/model/W1/Initializer/random_uniform/min (Const) \n  model/model/W1/Initializer/random_uniform/max (Const) \n  model/model/W1/Initializer/random_uniform/RandomUniform (RandomUniform) \n  model/model/W1/Initializer/random_uniform/sub (Sub) \n  model/model/W1/Initializer/random_uniform/mul (Mul) \n  model/model/W1/Initializer/random_uniform (Add) \n  model/model/W1 (VariableV2) /device:GPU:0\n  model/model/W1/Assign (Assign) /device:GPU:0\n  model/model/W1/read (Identity) /device:GPU:0\n  model/model/model/W1/Adam/Initializer/zeros (Const) /device:GPU:0\n  model/model/model/W1/Adam (VariableV2) /device:GPU:0\n  model/model/model/W1/Adam/Assign (Assign) /device:GPU:0\n  model/model/model/W1/Adam/read (Identity) /device:GPU:0\n  model/model/model/W1/Adam_1/Initializer/zeros (Const) /device:GPU:0\n  model/model/model/W1/Adam_1 (VariableV2) /device:GPU:0\n  model/model/model/W1/Adam_1/Assign (Assign) /device:GPU:0\n  model/model/model/W1/Adam_1/read (Identity) /device:GPU:0\n  model/Adam/update_model/model/W1/ApplyAdam (ApplyAdam) /device:GPU:0\n  model/save/Assign (Assign) /device:GPU:0\n\n\t [[node model/model/W1/Initializer/random_uniform/RandomUniform (defined at <ipython-input-6-43fb2aff1ac7>:4) ]]Additional information about colocations:No node-device colocations were active during op 'model/model/W1/Initializer/random_uniform/RandomUniform' creation.\nDevice assignments active during op 'model/model/W1/Initializer/random_uniform/RandomUniform' creation:\n  with tf.device(None): </home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py:1696>\n  with tf.device(/gpu:0): <<timed exec>:23>\n\nOriginal stack trace for 'model/model/W1/Initializer/random_uniform/RandomUniform':\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/shubham/.local/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/shubham/.local/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 378, in dispatch_queue\n    yield self.process_one()\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tornado/gen.py\", line 225, in wrapper\n    runner = Runner(result, future, yielded)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tornado/gen.py\", line 714, in __init__\n    self.run()\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n    return runner(coro)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/home/shubham/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-9-65b9bf2567f1>\", line 1, in <module>\n    get_ipython().run_cell_magic('time', '', \"# list_ds = tf.data.Dataset.list_files(train_dir)\\n# # Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\\n# training_dataset = list_ds.map(process_path, num_parallel_calls=5) \\nmodel = build_model(train_dir,learning_rate=learning_rate,epochs=epochs)\\nprint('works')\\n\")\n  File \"/home/shubham/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2359, in run_cell_magic\n    result = fn(*args, **kwargs)\n  File \"</home/shubham/.local/lib/python3.6/site-packages/decorator.py:decorator-gen-61>\", line 2, in time\n  File \"/home/shubham/.local/lib/python3.6/site-packages/IPython/core/magic.py\", line 187, in <lambda>\n    call = lambda f, *a, **k: f(*a, **k)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/IPython/core/magics/execution.py\", line 1310, in time\n    exec(code, glob, local_ns)\n  File \"<timed exec>\", line 4, in <module>\n  File \"<timed exec>\", line 24, in build_model\n  File \"<ipython-input-6-43fb2aff1ac7>\", line 4, in initialize_variables\n    W1 = tf.get_variable('W1',shape=[4,4,3,16],initializer=tf.contrib.layers.xavier_initializer())\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1496, in get_variable\n    aggregation=aggregation)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1239, in get_variable\n    aggregation=aggregation)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 562, in get_variable\n    aggregation=aggregation)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 514, in _true_getter\n    aggregation=aggregation)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 929, in _get_single_variable\n    aggregation=aggregation)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 259, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 220, in _variable_v1_call\n    shape=shape)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 198, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2511, in default_variable_creator\n    shape=shape)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 263, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 1568, in __init__\n    shape=shape)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 1698, in _init_from_args\n    initial_value(), name=\"initial_value\", dtype=dtype)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 901, in <lambda>\n    partition_info=partition_info)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/initializers.py\", line 145, in _initializer\n    dtype, seed=seed)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/ops/random_ops.py\", line 247, in random_uniform\n    rnd = gen_random_ops.random_uniform(shape, dtype, seed=seed1, seed2=seed2)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/ops/gen_random_ops.py\", line 820, in random_uniform\n    name=name)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1339\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m       \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation model/model/W1/Initializer/random_uniform/RandomUniform: Could not satisfy explicit device specification '' because the node {{colocation_node model/model/W1/Initializer/random_uniform/RandomUniform}} was colocated with a group of nodes that required incompatible device '/device:GPU:0'. All available devices [/job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_GPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0]. \nColocation Debug Info:\nColocation group had the following types and supported devices: \nRoot Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\nAssign: CPU \nIdentity: CPU XLA_CPU XLA_GPU \nVariableV2: CPU \nMul: CPU XLA_CPU XLA_GPU \nAdd: CPU XLA_CPU XLA_GPU \nSub: CPU XLA_CPU XLA_GPU \nRandomUniform: CPU XLA_CPU XLA_GPU \nApplyAdam: CPU \nConst: CPU XLA_CPU XLA_GPU \n\nColocation members, user-requested devices, and framework assigned devices, if any:\n  model/model/W1/Initializer/random_uniform/shape (Const) \n  model/model/W1/Initializer/random_uniform/min (Const) \n  model/model/W1/Initializer/random_uniform/max (Const) \n  model/model/W1/Initializer/random_uniform/RandomUniform (RandomUniform) \n  model/model/W1/Initializer/random_uniform/sub (Sub) \n  model/model/W1/Initializer/random_uniform/mul (Mul) \n  model/model/W1/Initializer/random_uniform (Add) \n  model/model/W1 (VariableV2) /device:GPU:0\n  model/model/W1/Assign (Assign) /device:GPU:0\n  model/model/W1/read (Identity) /device:GPU:0\n  model/model/model/W1/Adam/Initializer/zeros (Const) /device:GPU:0\n  model/model/model/W1/Adam (VariableV2) /device:GPU:0\n  model/model/model/W1/Adam/Assign (Assign) /device:GPU:0\n  model/model/model/W1/Adam/read (Identity) /device:GPU:0\n  model/model/model/W1/Adam_1/Initializer/zeros (Const) /device:GPU:0\n  model/model/model/W1/Adam_1 (VariableV2) /device:GPU:0\n  model/model/model/W1/Adam_1/Assign (Assign) /device:GPU:0\n  model/model/model/W1/Adam_1/read (Identity) /device:GPU:0\n  model/Adam/update_model/model/W1/ApplyAdam (ApplyAdam) /device:GPU:0\n  model/save/Assign (Assign) /device:GPU:0\n\n\t [[{{node model/model/W1/Initializer/random_uniform/RandomUniform}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-aa94825f7315>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-d2bcabd50b16>\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(test_dir)\u001b[0m\n\u001b[1;32m     10\u001b[0m           \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m           \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m           \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAINABLE_VARIABLES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;31m#  tf.reset_default_graph()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1368\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation model/model/W1/Initializer/random_uniform/RandomUniform: Could not satisfy explicit device specification '' because the node node model/model/W1/Initializer/random_uniform/RandomUniform (defined at <ipython-input-6-43fb2aff1ac7>:4) placed on device Device assignments active during op 'model/model/W1/Initializer/random_uniform/RandomUniform' creation:\n  with tf.device(None): </home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py:1696>\n  with tf.device(/gpu:0): <<timed exec>:23>  was colocated with a group of nodes that required incompatible device '/device:GPU:0'. All available devices [/job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_GPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0]. \nColocation Debug Info:\nColocation group had the following types and supported devices: \nRoot Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\nAssign: CPU \nIdentity: CPU XLA_CPU XLA_GPU \nVariableV2: CPU \nMul: CPU XLA_CPU XLA_GPU \nAdd: CPU XLA_CPU XLA_GPU \nSub: CPU XLA_CPU XLA_GPU \nRandomUniform: CPU XLA_CPU XLA_GPU \nApplyAdam: CPU \nConst: CPU XLA_CPU XLA_GPU \n\nColocation members, user-requested devices, and framework assigned devices, if any:\n  model/model/W1/Initializer/random_uniform/shape (Const) \n  model/model/W1/Initializer/random_uniform/min (Const) \n  model/model/W1/Initializer/random_uniform/max (Const) \n  model/model/W1/Initializer/random_uniform/RandomUniform (RandomUniform) \n  model/model/W1/Initializer/random_uniform/sub (Sub) \n  model/model/W1/Initializer/random_uniform/mul (Mul) \n  model/model/W1/Initializer/random_uniform (Add) \n  model/model/W1 (VariableV2) /device:GPU:0\n  model/model/W1/Assign (Assign) /device:GPU:0\n  model/model/W1/read (Identity) /device:GPU:0\n  model/model/model/W1/Adam/Initializer/zeros (Const) /device:GPU:0\n  model/model/model/W1/Adam (VariableV2) /device:GPU:0\n  model/model/model/W1/Adam/Assign (Assign) /device:GPU:0\n  model/model/model/W1/Adam/read (Identity) /device:GPU:0\n  model/model/model/W1/Adam_1/Initializer/zeros (Const) /device:GPU:0\n  model/model/model/W1/Adam_1 (VariableV2) /device:GPU:0\n  model/model/model/W1/Adam_1/Assign (Assign) /device:GPU:0\n  model/model/model/W1/Adam_1/read (Identity) /device:GPU:0\n  model/Adam/update_model/model/W1/ApplyAdam (ApplyAdam) /device:GPU:0\n  model/save/Assign (Assign) /device:GPU:0\n\n\t [[node model/model/W1/Initializer/random_uniform/RandomUniform (defined at <ipython-input-6-43fb2aff1ac7>:4) ]]Additional information about colocations:No node-device colocations were active during op 'model/model/W1/Initializer/random_uniform/RandomUniform' creation.\nDevice assignments active during op 'model/model/W1/Initializer/random_uniform/RandomUniform' creation:\n  with tf.device(None): </home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py:1696>\n  with tf.device(/gpu:0): <<timed exec>:23>\n\nOriginal stack trace for 'model/model/W1/Initializer/random_uniform/RandomUniform':\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/shubham/.local/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/shubham/.local/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 378, in dispatch_queue\n    yield self.process_one()\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tornado/gen.py\", line 225, in wrapper\n    runner = Runner(result, future, yielded)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tornado/gen.py\", line 714, in __init__\n    self.run()\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n    return runner(coro)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/home/shubham/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-9-65b9bf2567f1>\", line 1, in <module>\n    get_ipython().run_cell_magic('time', '', \"# list_ds = tf.data.Dataset.list_files(train_dir)\\n# # Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\\n# training_dataset = list_ds.map(process_path, num_parallel_calls=5) \\nmodel = build_model(train_dir,learning_rate=learning_rate,epochs=epochs)\\nprint('works')\\n\")\n  File \"/home/shubham/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2359, in run_cell_magic\n    result = fn(*args, **kwargs)\n  File \"</home/shubham/.local/lib/python3.6/site-packages/decorator.py:decorator-gen-61>\", line 2, in time\n  File \"/home/shubham/.local/lib/python3.6/site-packages/IPython/core/magic.py\", line 187, in <lambda>\n    call = lambda f, *a, **k: f(*a, **k)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/IPython/core/magics/execution.py\", line 1310, in time\n    exec(code, glob, local_ns)\n  File \"<timed exec>\", line 4, in <module>\n  File \"<timed exec>\", line 24, in build_model\n  File \"<ipython-input-6-43fb2aff1ac7>\", line 4, in initialize_variables\n    W1 = tf.get_variable('W1',shape=[4,4,3,16],initializer=tf.contrib.layers.xavier_initializer())\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1496, in get_variable\n    aggregation=aggregation)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1239, in get_variable\n    aggregation=aggregation)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 562, in get_variable\n    aggregation=aggregation)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 514, in _true_getter\n    aggregation=aggregation)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 929, in _get_single_variable\n    aggregation=aggregation)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 259, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 220, in _variable_v1_call\n    shape=shape)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 198, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2511, in default_variable_creator\n    shape=shape)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 263, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 1568, in __init__\n    shape=shape)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 1698, in _init_from_args\n    initial_value(), name=\"initial_value\", dtype=dtype)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 901, in <lambda>\n    partition_info=partition_info)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/initializers.py\", line 145, in _initializer\n    dtype, seed=seed)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/ops/random_ops.py\", line 247, in random_uniform\n    rnd = gen_random_ops.random_uniform(shape, dtype, seed=seed1, seed2=seed2)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/ops/gen_random_ops.py\", line 820, in random_uniform\n    name=name)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "test_model(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
