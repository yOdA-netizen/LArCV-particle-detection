{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = os.path.dirname(os.path.realpath('__file__'))\n",
    "#train_dir = home_dir+'/data/image_format_single_plane/plane-xy/*/*'\n",
    "train_dir = home_dir+'/data/image_format_small_dataset/*/*'\n",
    "\n",
    "vocab = ['electrons','protons','muons','pions','gamma']\n",
    "image_size = 256\n",
    "\n",
    "minibatch_size = 256 \n",
    "epochs = 1000\n",
    "learning_rate=0.0001\n",
    "training_size = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "  # convert the path to a list of path components and one hot them\n",
    "    parts = tf.string_split([file_path], '/')\n",
    "    label = parts.values[-2] \n",
    "    matches = tf.stack([tf.equal(label, s) for s in vocab], axis=-1)\n",
    "    onehot = tf.cast(matches, tf.float32)\n",
    "    return onehot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_img(img):\n",
    "  # convert the compressed string to a uint8 tensor\n",
    "  img = tf.image.decode_jpeg(img, channels=3)\n",
    "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "  # resize the image to the desired size.\n",
    "  img = tf.image.per_image_standardization(img)\n",
    "  return tf.image.resize(img, [image_size, image_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_path(file_path):\n",
    "  label = get_label(file_path)\n",
    "  # load the raw data from the file as a string\n",
    "  img = tf.io.read_file(file_path)\n",
    "  img = decode_img(img)\n",
    "  return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_variables():\n",
    "    with tf.variable_scope('model',reuse=tf.AUTO_REUSE):\n",
    "        \n",
    "        #Wn is filter for nth cnn layer. shape is (height,width,in_channel,out_channel)\n",
    "        W1 = tf.get_variable('W1',shape=[11,11,3,128],initializer=tf.contrib.layers.xavier_initializer())\n",
    "        W2 = tf.get_variable('W2',shape=[5,5,128,256],initializer= tf.contrib.layers.xavier_initializer())\n",
    "        W3 = tf.get_variable('W3',shape=[3,3,256,128],initializer= tf.contrib.layers.xavier_initializer())\n",
    "        W4 = tf.get_variable('W4',shape=[3,3,128,64],initializer= tf.contrib.layers.xavier_initializer())\n",
    "        W5 = tf.get_variable('W5',shape=[3,3,64,32],initializer= tf.contrib.layers.xavier_initializer())\n",
    "        \n",
    "        \n",
    "        parameters = {'W1':W1, 'W2':W2, 'W3':W3, 'W4':W4, 'W5':W5}\n",
    "    return parameters\n",
    "\n",
    "\n",
    "def forward_prop(X,parameters):\n",
    "    '''Arguments:\n",
    "               X of shape (num_featues,batch_size)\n",
    "               parameters-- dictionary of parameters\n",
    "      Returns:\n",
    "      logits-- without calculating activation function on the last layer as the cost function doesn't need it. \n",
    "    '''\n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    W3 = parameters['W3']\n",
    "    W4 = parameters['W4']\n",
    "    W5 = parameters['W5']\n",
    "    \n",
    "    \n",
    "    #Z = tf.nn.conv2d(input,Weights,strides=[1,stride_y,stride_x,1],padding='VALID')\n",
    "    #tf.nn.max_pool(x, ksize=[1, filter_height, filter_width, 1],strides = [1, stride_y, stride_x, 1],padding = padding, name = name)\n",
    "\n",
    "    Z1 = tf.nn.conv2d(X,W1,strides=[1,4,4,1],padding='VALID')\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    P1 = tf.nn.max_pool(A1,ksize=[1,3,3,1],strides=[1,2,2,1],padding='VALID') \n",
    "    \n",
    "    Z2 = tf.nn.conv2d(P1,W2, strides=[1,1,1,1],padding='VALID')\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    P2 = tf.nn.max_pool(A2,ksize=[1,3,3,1],strides=[1,2,2,1],padding='VALID') \n",
    "   \n",
    "    \n",
    "    Z3 = tf.nn.conv2d(P2,W3, strides=[1,1,1,1],padding='VALID')\n",
    "    A3 = tf.nn.relu(Z3)\n",
    "    \n",
    "    Z4 = tf.nn.conv2d(Z3,W4, strides=[1,1,1,1],padding='VALID')\n",
    "    A4 = tf.nn.relu(Z4)\n",
    "                     \n",
    "    Z5 = tf.nn.conv2d(Z4,W5, strides=[1,1,1,1],padding='VALID')\n",
    "    A5 = tf.nn.relu(Z5)\n",
    "    P5 = tf.nn.max_pool(A5,ksize=[1,3,3,1],strides=[1,2,2,1],padding='VALID') \n",
    "   \n",
    "    f1 = tf.contrib.layers.flatten(P5)   \n",
    "    logits = tf.contrib.layers.fully_connected(f1,5,activation_fn=None)\n",
    "    \n",
    "    return logits\n",
    "\n",
    "\n",
    "def compute_cost(Z,Y):\n",
    "    logits = tf.transpose(Z)\n",
    "    labels = tf.transpose(Y)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits,labels = labels))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17055483043942577046\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 12117218164753614503\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 8444618634902605276\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 µs, sys: 0 ns, total: 6 µs\n",
      "Wall time: 10.3 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def model(training_dataset,learning_rate=0.00002,epochs=10):   \n",
    "    \n",
    "    with tf.variable_scope('model',reuse=tf.AUTO_REUSE):\n",
    "        with tf.device('/cpu:0'):\n",
    "            batched_training_dataset = training_dataset.batch(minibatch_size).prefetch(1)\n",
    "            iterator = tf.data.Iterator.from_structure(batched_training_dataset.output_types,batched_training_dataset.output_shapes)\n",
    "\n",
    "            training_init_op = iterator.make_initializer(batched_training_dataset)\n",
    "    #        validation_init_op = iterator.make_initializer(batched_validation_dataset)\n",
    "            next_element = iterator.get_next()\n",
    "            data = next_element     \n",
    "            X = data[0]\n",
    "            Y = data[1]\n",
    "    #        assert(X.get_shape == (minibatch_size))\n",
    "            # assert(Y.shape == (depth,minibatch_size))\n",
    "        \n",
    "        with tf.device('/gpu:0'):\n",
    "            parameters = initialize_variables()\n",
    "            logits =  forward_prop(X,parameters)    \n",
    "            \n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "            \n",
    "            predictions = tf.one_hot(tf.reshape(tf.argmax(logits,axis=1),shape=[-1,1]),depth=5,axis=1)\n",
    "            #labels = tf.reshape(tf.argmax(Y,axis=1), shape=[-1,1])\n",
    "            labels = Y\n",
    "           # assert(predictions.shape==labels.shape)\n",
    "            print('Y shape:',Y.get_shape())\n",
    "            \n",
    "            accuracy_calculator,accuracy_updater = tf.metrics.accuracy(predictions=predictions,labels=labels,name='metric')\n",
    "            running_vars = tf.get_collection(tf.GraphKeys.LOCAL_VARIABLES,scope = 'metric')\n",
    "            running_vars_initializer = tf.variables_initializer(var_list=running_vars)\n",
    "            saver = tf.train.Saver(parameters, max_to_keep=1)\n",
    "        \n",
    "        \n",
    "        with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)) as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            sess.run(tf.local_variables_initializer())\n",
    "            num_minibatches  = int(training_size/minibatch_size)\n",
    "            for epoch in range(epochs):\n",
    "                sess.run(running_vars_initializer)\n",
    "                epoch_cost = 0                \n",
    "                sess.run(training_init_op)\n",
    "                while True:\n",
    "                    try:\n",
    "                        _, cost = sess.run([optimizer,loss])\n",
    "                        sess.run(accuracy_updater)\n",
    "                        print('cost: {0} of epoch {1}'.format(cost,epoch))\n",
    "                        epoch_cost = epoch_cost + cost\n",
    "#                         print('predictions:',sess.run(predictions))\n",
    "#                         print('labels: ',sess.run(labels))\n",
    "#                         print('Y: ',sess.run(Y))\n",
    "#                         print('logits:',sess.run(logits))\n",
    "                    except tf.errors.OutOfRangeError:\n",
    "                        if epoch%10 == 0:\n",
    "                            accuracy = sess.run(accuracy_calculator)  \n",
    "                            epoch_cost = epoch_cost/num_minibatches\n",
    "                            print(' accuracy is {1} for epoch {0} with cost {2}'.format(epoch,accuracy,epoch_cost))\n",
    "                        break\n",
    "\n",
    "            print(\"Final accuracy \" + str(sess.run(accuracy_calculator)))\n",
    "\n",
    "            saver.save(sess, home_dir+'weights/model_parameters')\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2794339128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2794339128>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2794339128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2794339128>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2794339518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2794339518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2794339518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2794339518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "Y shape: (?, 5)\n",
      " accuracy is 0.6721311211585999 for epoch 0 with cost 170.66713256835936\n",
      " accuracy is 0.6794337034225464 for epoch 10 with cost 1381.52099609375\n",
      " accuracy is 0.6792089343070984 for epoch 20 with cost 18771.558984375\n",
      " accuracy is 0.6805393695831299 for epoch 30 with cost 188925.15625\n",
      " accuracy is 0.680194616317749 for epoch 40 with cost 1264776.9\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "list_ds = tf.data.Dataset.list_files(train_dir)\n",
    "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
    "training_dataset = list_ds.map(process_path, num_parallel_calls=8) \n",
    "model(training_dataset,learning_rate=learning_rate,epochs=epochs)\n",
    "print('works')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
