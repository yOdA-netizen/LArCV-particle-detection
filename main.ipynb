{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/ops/image_ops_impl.py:1514: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/data/experimental/ops/readers.py:499: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n"
     ]
    }
   ],
   "source": [
    "!rm -rf ./logs/ \n",
    "%run Model.ipynb\n",
    "%run dataset_loader.ipynb\n",
    "import tensorflow as tf\n",
    "import numpy\n",
    "import sys\n",
    "#from dataset_loader import load_dataset\n",
    "\n",
    "test_no = 46\n",
    "\n",
    "#tf.enable_eager_execution()\n",
    "INPUT_WIDTH = 64\n",
    "INPUT_HEIGHT = 65\n",
    "\n",
    "INPUT_SIZE = 64\n",
    "\n",
    "INPUT_CHANNELS = 1\n",
    "\n",
    "NUM_CLASSES = 5\n",
    "\n",
    "LEARNING_RATE = 0.01  # Original value: 0.01\n",
    "DECAY_POINT = 100\n",
    "DECAY_RATE = 100\n",
    "\n",
    "\n",
    "\n",
    "DROPOUT_RATE = 0\n",
    "\n",
    "EPOCHS = 4000\n",
    "GLOBAL_STEPS = 100\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "NUM_PARRALLEL_THREADS = 8\n",
    "\n",
    "GRAYSCALE=True\n",
    "IS_FREQUENCY = True\n",
    "\n",
    "RESTORE = True\n",
    "\n",
    "train_sub_dir = '/data/image_format/training_data_15000/*/*'\n",
    "val_sub_dir = '/data/image_format/validation_data/*/*'\n",
    "test_sub_dir = '/data/image_format/test_data/*/*'\n",
    "\n",
    "\n",
    "# train_sub_dir = '/data/medium_dataset/medium_dataset_train/*/*'\n",
    "# val_sub_dir = '/data/medium_dataset/medium_dataset_val/*/*'\n",
    "# test_sub_dir = '/data/medium_dataset/medium_dataset_test/*/*'\n",
    "\n",
    "\n",
    "\n",
    "frequency_train_sub_dir = '/data/cogisen_frequency_data/training_data_15000_cogisen/*/*/*.csv'\n",
    "frequency_val_sub_dir = '/data/cogisen_frequency_data/validation_data_1500_cogisen/*/*/*.csv'\n",
    "frequency_test_sub_dir = '/data/cogisen_frequency_data/test_data_1500_cogisen/*/*/*.csv'\n",
    "\n",
    "\n",
    "home_dir = os.path.dirname(os.path.realpath('__file__'))\n",
    "\n",
    "train_dir = home_dir + train_sub_dir\n",
    "val_dir = home_dir + val_sub_dir\n",
    "test_dir = home_dir + test_sub_dir\n",
    "\n",
    "\n",
    "frequency_train_dir = home_dir + frequency_train_sub_dir\n",
    "frequency_val_dir = home_dir + frequency_val_sub_dir\n",
    "frequency_test_dir = home_dir + frequency_test_sub_dir\n",
    "\n",
    "\n",
    "\n",
    "training_dataset= load_dataset(img_dir= train_dir,frequency_dir=frequency_train_dir,minibatch_size=BATCH_SIZE,image_size=INPUT_SIZE,grayscale=GRAYSCALE,num_parallel_calls=NUM_PARRALLEL_THREADS,is_frequency=IS_FREQUENCY)\n",
    "\n",
    "# logdir = './log/simple_model/frequency_data/grayscale'+str(experiment_no)\n",
    "# weight_dir = './weights/simple_model/frequency_data/grayscale/'+str(experiment_no)+'/model'\n",
    "\n",
    "\n",
    "logdir = home_dir+'/log/2_test/test/' + str(test_no)\n",
    "\n",
    "weight_dir = home_dir+'/weights/test/' +str(test_no)\n",
    "\n",
    "weights = weight_dir +'/model'\n",
    "if not os.path.exists(weight_dir):\n",
    "    os.makedirs(os.path.join(weight_dir))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'XLA_GPU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/device:XLA_GPU:0']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-c8fd937ffc9a>:4: DatasetV1.output_types (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_types(dataset)`.\n",
      "WARNING:tensorflow:From <ipython-input-4-c8fd937ffc9a>:4: DatasetV1.output_shapes (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_shapes(dataset)`.\n",
      "WARNING:tensorflow:From /home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py:348: Iterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_types(iterator)`.\n",
      "WARNING:tensorflow:From /home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py:349: Iterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_shapes(iterator)`.\n",
      "WARNING:tensorflow:From /home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py:351: Iterator.output_classes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_classes(iterator)`.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "handle = tf.placeholder(tf.string, shape=[],name=\"data_handle\")\n",
    "\n",
    "with tf.name_scope('iterators'):\n",
    "    training_iterator = tf.data.Iterator.from_structure(training_dataset.output_types,training_dataset.output_shapes)\n",
    "    training_init_op = training_iterator.make_initializer(training_dataset)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = tf.data.Iterator.from_string_handle(\n",
    "    handle, training_iterator.output_types,training_dataset.output_shapes)\n",
    "\n",
    "next_training_element = iterator.get_next()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 4, 3, 16]\n"
     ]
    }
   ],
   "source": [
    "#with tf.device('/device:XLA_GPU:0'):\n",
    "model = Simple_Model(next_training_element,input_height=INPUT_HEIGHT,input_width=INPUT_WIDTH, num_classes=NUM_CLASSES,input_channels=INPUT_CHANNELS,dropout_rate=DROPOUT_RATE,learning_rate=LEARNING_RATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#train_sub_dir = '/data/image_format/training_data_1500/*/*'\n",
    "val_dataset = load_dataset(img_dir= val_dir,frequency_dir=frequency_val_dir,minibatch_size=1500,image_size=INPUT_SIZE,grayscale=GRAYSCALE,num_parallel_calls=NUM_PARRALLEL_THREADS,is_frequency=IS_FREQUENCY)\n",
    "\n",
    "val_iterator = tf.data.Iterator.from_structure(val_dataset.output_types,val_dataset.output_shapes)\n",
    "val_init_op = val_iterator.make_initializer(val_dataset,name='val_init_op')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for training set for epoch 0 is  :  0.15131579339504242\n",
      "accuracy for validation set for epoch 0 is  :  0.23533333837985992 and loss is 352791101440.0\n",
      "accuracy for training set for epoch 5 is  :  0.22368420660495758\n",
      "accuracy for validation set for epoch 5 is  :  0.1993333399295807 and loss is 14467240960.0\n",
      "accuracy for training set for epoch 10 is  :  0.22368420660495758\n",
      "accuracy for validation set for epoch 10 is  :  0.21799999475479126 and loss is 3867141888.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# if RESTORE:\n",
    "#     tf.reset_default_graph()\n",
    "#     graph = tf.get_default_graph()\n",
    "#     saver = tf.train.import_meta_graph(meta_dir)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with tf.device('/device:XLA_GPU:0'):\n",
    "\n",
    "    with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)) as sess:\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "     \n",
    "        file_writer = tf.summary.FileWriter(logdir=logdir, graph=sess.graph)\n",
    "\n",
    "        \n",
    "        summary_operation = tf.summary.merge_all()\n",
    "        \n",
    "        saver = tf.train.Saver()\n",
    "        saver.save(sess, weights)\n",
    "        training_string_handle =  sess.run(training_iterator.string_handle())\n",
    "        val_handle = sess.run(val_iterator.string_handle())\n",
    "        numpy.set_printoptions(threshold=sys.maxsize)\n",
    "        \n",
    "        # Original value: 0.01\n",
    "        for epoch in range(EPOCHS):\n",
    "            \n",
    "            sess.run(training_init_op,feed_dict={handle:training_string_handle})\n",
    "            saver.save(sess, weights,global_step=GLOBAL_STEPS,write_meta_graph=False)\n",
    "            \n",
    "            if epoch == DECAY_POINT:\n",
    "                LEARNING_RATE = LEARNING_RATE/DECAY_RATE\n",
    "                \n",
    "            while True:\n",
    "                try:\n",
    "                    _, train_accuracy,summary,predictions,input_image,logits= sess.run([model.training_operation,model.accuracy_operation,summary_operation,model.predictions,model.X,model.logits],feed_dict={handle:training_string_handle,model.learning_rate:LEARNING_RATE})\n",
    "                   # predictions,input_image,logits= sess.run([model.predictions,model.X,model.logits],feed_dict={handle:training_string_handle, learning_rate:LEARNING_RATE})\n",
    "                   # print(\"input_image: {0}\".format(input_image))\n",
    "                   \n",
    "                    \n",
    "                \n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    \n",
    "                    file_writer.add_summary(summary, epoch)\n",
    "                    \n",
    "                    if epoch%5 ==0:\n",
    "                        print(\"accuracy for training set for epoch {0} is  :  {1}\".format(epoch,train_accuracy))            \n",
    "                  #  print(\"predictions: {0}\".format(predictions))\n",
    "                    break\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            if epoch%5 ==0:\n",
    "                sess.run(val_init_op,feed_dict={handle:val_handle})\n",
    "            \n",
    "\n",
    "                while True:\n",
    "                    try:\n",
    "\n",
    "                        val_accuracy,loss = sess.run([model.accuracy_operation,model.loss],feed_dict={handle:val_handle})\n",
    "                    \n",
    "    #                     val_summary = tf.summary.scalar(name='val_accuracy', data=val_accuracy)\n",
    "    #                     file_writer.add_summary(val_summary,epoch)\n",
    "                       # val_accuracy = val_accuracy + val_batch_accuracy\n",
    "              \n",
    "\n",
    "                    except tf.errors.OutOfRangeError:\n",
    "                        #val_accuracy = val_accuracy/validation_batches\n",
    "                        print(\"accuracy for validation set for epoch {0} is  :  {1} and loss is {2}\".format(epoch,val_accuracy,loss))\n",
    "\n",
    "                        break\n",
    "\n",
    "\n",
    "                \n",
    "                \n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "                \n",
    "            \n",
    "           \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_dir = weights+'.meta'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "graph = tf.get_default_graph()\n",
    "saver = tf.train.import_meta_graph(meta_dir)\n",
    "\n",
    "val_dataset = load_dataset(img_dir= val_dir,frequency_dir=frequency_val_dir,minibatch_size=1500,image_size=INPUT_SIZE,grayscale=GRAYSCALE,num_parallel_calls=NUM_PARRALLEL_THREADS,is_frequency=IS_FREQUENCY)\n",
    "\n",
    "val_iterator = tf.data.Iterator.from_structure(val_dataset.output_types,val_dataset.output_shapes)\n",
    "val_init_op = val_iterator.make_initializer(val_dataset,name='val_init_op')\n",
    " \n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)) as sess:\n",
    "    \n",
    "    \n",
    "    print('validation dataset...')\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess, tf.train.latest_checkpoint(weight_dir))\n",
    "   \n",
    "    iterator_handle = graph.get_tensor_by_name('data_handle:0')\n",
    "    val_handle = sess.run(val_iterator.string_handle())\n",
    "    \n",
    "\n",
    "    \n",
    "    sess.run(val_init_op,feed_dict={iterator_handle:val_handle})\n",
    "\n",
    "    accuracy_op = graph.get_tensor_by_name('accuracy/accuracy_operation:0')\n",
    "   \n",
    "    while True:\n",
    "        try:\n",
    "            val_accuracy = sess.run([accuracy_op],feed_dict={iterator_handle:val_handle})\n",
    "\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"accuracy for validation set :  {0}\".format(val_accuracy))\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "graph = tf.get_default_graph()\n",
    "saver = tf.train.import_meta_graph(meta_dir)\n",
    "\n",
    "test_dataset = load_dataset(img_dir= test_dir,frequency_dir=frequency_test_dir,minibatch_size=1500,image_size=INPUT_SIZE,grayscale=GRAYSCALE,num_parallel_calls=NUM_PARRALLEL_THREADS,is_frequency=IS_FREQUENCY)\n",
    "\n",
    "test_iterator = tf.data.Iterator.from_structure(test_dataset.output_types,test_dataset.output_shapes)\n",
    "test_init_op = test_iterator.make_initializer(test_dataset,name='test_init_op')\n",
    "\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)) as sess:\n",
    "    \n",
    "    \n",
    "    print('testing dataset...')\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess, tf.train.latest_checkpoint(weight_dir))\n",
    "   # val_op = graph.get_operation_by_name(\"iterators/val_init_op\")\n",
    "    iterator_handle = graph.get_tensor_by_name('data_handle:0')\n",
    "    test_handle = sess.run(test_iterator.string_handle())\n",
    "\n",
    "    \n",
    "    sess.run(test_init_op,feed_dict={iterator_handle:test_handle})\n",
    "\n",
    "    accuracy_op = graph.get_tensor_by_name('accuracy/accuracy_operation:0')\n",
    "   \n",
    "    while True:\n",
    "        try:\n",
    "            test_accuracy = sess.run([accuracy_op],feed_dict={iterator_handle:test_handle})\n",
    "\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"accuracy for testing set :  {0}\".format(test_accuracy))\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
