{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1 µs, sys: 0 ns, total: 1 µs\n",
      "Wall time: 4.77 µs\n",
      "WARNING:tensorflow:From <ipython-input-1-5745e119ea4b>:16: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/data/experimental/ops/readers.py:499: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n"
     ]
    }
   ],
   "source": [
    "!rm -rf ./logs/ \n",
    "%run Model.ipynb\n",
    "%run dataset_loader.ipynb\n",
    "import tensorflow as tf\n",
    "#from dataset_loader import load_dataset\n",
    "\n",
    "#tf.enable_eager_execution()\n",
    "INPUT_WIDTH = 64\n",
    "INPUT_HEIGHT = 65\n",
    "\n",
    "INPUT_SIZE = 64\n",
    "\n",
    "INPUT_CHANNELS = 3\n",
    "\n",
    "NUM_CLASSES = 5\n",
    "\n",
    "LEARNING_RATE = 0.0005   # Original value: 0.01\n",
    "MOMENTUM = 0.9\n",
    "KEEP_PROB = 1\n",
    "\n",
    "EPOCHS = 2000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "NUM_PARRALLEL_THREADS = 12\n",
    "\n",
    "train_sub_dir = '/data/image_format_small_dataset/*/*'\n",
    "val_sub_dir = '/data/image_format_small_dataset_val/*/*'\n",
    "test_sub_dir = '/data/image_format_small_dataset_test/*/*'\n",
    "\n",
    "frequency_train_sub_dir = '/data/cogisen_frequency_data/image_format_small_dataset_cogisen_updated/*/*/*.csv'\n",
    "frequency_val_sub_dir = '/data/image_format_small_dataset_val_cogisen_updated/*/*/*.csv'\n",
    "frequency_test_sub_dir = '/data/image_format_small_dataset_test_cogisen_updated/*/*/*.csv'\n",
    "\n",
    "\n",
    "home_dir = os.path.dirname(os.path.realpath('__file__'))\n",
    "\n",
    "train_dir = home_dir + train_sub_dir\n",
    "val_dir = home_dir + val_sub_dir\n",
    "test_dir = home_dir + test_sub_dir\n",
    "\n",
    "\n",
    "frequency_train_dir = home_dir + frequency_train_sub_dir\n",
    "frequency_val_dir = home_dir + frequency_val_sub_dir\n",
    "frequency_test_dir = home_dir + frequency_test_sub_dir\n",
    "\n",
    "\n",
    "\n",
    "training_dataset= load_dataset(img_dir= train_dir,frequency_dir=frequency_train_dir,minibatch_size=BATCH_SIZE,image_size=INPUT_SIZE,grayscale=True,num_parallel_calls=NUM_PARRALLEL_THREADS)\n",
    "\n",
    "\n",
    "val_dataset = load_dataset(img_dir= val_dir,frequency_dir=frequency_train_dir,minibatch_size=BATCH_SIZE,image_size=INPUT_SIZE,grayscale=True,num_parallel_calls=NUM_PARRALLEL_THREADS)\n",
    "\n",
    "test_dataset = load_dataset(img_dir= test_dir,frequency_dir=frequency_train_dir,minibatch_size=BATCH_SIZE,image_size=INPUT_SIZE,grayscale=True,num_parallel_calls=NUM_PARRALLEL_THREADS)\n",
    "\n",
    "experiment_no = 2\n",
    "#logdir = './log/alexnet/FULL_DATA'+str(experiment_no)\n",
    "logdir = './log/frequency_data/grayscale+normalized' +str(experiment_no)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'XLA_GPU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/device:XLA_GPU:0']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-a0b3af110868>:4: DatasetV1.output_types (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_types(dataset)`.\n",
      "WARNING:tensorflow:From <ipython-input-4-a0b3af110868>:4: DatasetV1.output_shapes (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_shapes(dataset)`.\n",
      "WARNING:tensorflow:From /home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py:348: Iterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_types(iterator)`.\n",
      "WARNING:tensorflow:From /home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py:349: Iterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_shapes(iterator)`.\n",
      "WARNING:tensorflow:From /home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py:351: Iterator.output_classes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_classes(iterator)`.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "handle = tf.placeholder(tf.string, shape=[])\n",
    "\n",
    "\n",
    "training_iterator = tf.data.Iterator.from_structure(training_dataset.output_types,training_dataset.output_shapes)\n",
    "training_init_op = training_iterator.make_initializer(training_dataset)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = tf.data.Iterator.from_string_handle(\n",
    "    handle, training_iterator.output_types,training_dataset.output_shapes)\n",
    "\n",
    "next_training_element = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Y shape:  (?, 5)\n",
      "layer8_logits:  (?, 5)\n"
     ]
    }
   ],
   "source": [
    "#with tf.device('/device:XLA_GPU:0'):\n",
    "alexnet = AlexNet(next_training_element,input_height=INPUT_HEIGHT,input_width=INPUT_WIDTH, num_classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset...\n",
      "accuracy for epoch 0  :  0.1071428582072258\n",
      "accuracy for epoch 1  :  0.1428571492433548\n",
      "accuracy for epoch 2  :  0.1071428582072258\n",
      "accuracy for epoch 3  :  0.2142857164144516\n",
      "accuracy for epoch 4  :  0.1428571492433548\n",
      "accuracy for epoch 5  :  0.25\n",
      "accuracy for epoch 6  :  0.2142857164144516\n",
      "accuracy for epoch 7  :  0.1785714328289032\n",
      "accuracy for epoch 8  :  0.1785714328289032\n",
      "accuracy for epoch 9  :  0.2142857164144516\n",
      "accuracy for epoch 10  :  0.1428571492433548\n",
      "accuracy for epoch 11  :  0.1071428582072258\n",
      "accuracy for epoch 12  :  0.2142857164144516\n",
      "accuracy for epoch 13  :  0.25\n",
      "accuracy for epoch 14  :  0.1428571492433548\n",
      "accuracy for epoch 15  :  0.2857142984867096\n",
      "accuracy for epoch 16  :  0.25\n",
      "accuracy for epoch 17  :  0.1428571492433548\n",
      "accuracy for epoch 18  :  0.1785714328289032\n",
      "accuracy for epoch 19  :  0.25\n",
      "accuracy for epoch 20  :  0.2142857164144516\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:XLA_GPU:0'):\n",
    "\n",
    "    with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)) as sess:\n",
    "        print('Training dataset...')\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.local_variables_initializer())\n",
    "        file_writer = tf.summary.FileWriter(logdir=logdir, graph=sess.graph)\n",
    "\n",
    "        training_string_handle =  sess.run(training_iterator.string_handle())\n",
    "\n",
    "        summary_operation = tf.summary.merge_all()\n",
    "\n",
    "        for epoch in range(EPOCHS):\n",
    "            sess.run(training_init_op,feed_dict={handle:training_string_handle})\n",
    "            while True:\n",
    "                try:\n",
    "                    _, accuracy,summary,Y,final_logits= sess.run([alexnet.training_operation,alexnet.accuracy_operation,summary_operation,alexnet.Y,alexnet.final_logits],feed_dict={alexnet.dropout_keep_prob: alexnet.keep_prob,handle:training_string_handle})\n",
    "                    \n",
    "\n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    file_writer.add_summary(summary, epoch)\n",
    "                    print(\"accuracy for epoch {0}  :  {1}\".format(epoch,accuracy))\n",
    "                    break\n",
    "\n",
    "            #print(\"Y: \",Y)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "val_iterator = tf.data.Iterator.from_structure(val_dataset.output_types,val_dataset.output_shapes)\n",
    "val_init_op = val_iterator.make_initializer(val_dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)) as sess:\n",
    "    print('validation dataset...')\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(val_init_op)\n",
    "    val_string_handle =  sess.run(val_iterator.string_handle())\n",
    "    val_accuracy = sess.run([alexnet.accuracy_operation],feed_dict={alexnet.dropout_keep_prob: alexnet.keep_prob, \n",
    "                                                                     handle:val_string_handle})\n",
    "    \n",
    "\n",
    "    print(\"accuracy for validation set :  {0}\".format(val_accuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_iterator = tf.data.Iterator.from_structure(test_dataset.output_types,test_dataset.output_shapes)\n",
    "test_init_op = test_iterator.make_initializer(test_dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)) as sess:\n",
    "    print('Testing dataset...')\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    \n",
    "    sess.run(test_init_op)\n",
    "    test_string_handle =  sess.run(test_iterator.string_handle())\n",
    "    test_accuracy = sess.run([alexnet.accuracy_operation],feed_dict={alexnet.dropout_keep_prob: alexnet.keep_prob, \n",
    "                                                                     handle:test_string_handle})\n",
    "    \n",
    "\n",
    "    print(\"accuracy for test set :  {0}\".format(test_accuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
