{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-9feb52b22e0e>:9: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/data/experimental/ops/readers.py:499: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n"
     ]
    }
   ],
   "source": [
    "!rm -rf ./logs/ \n",
    "%run Model.ipynb\n",
    "%run dataset_loader.ipynb\n",
    "import tensorflow as tf\n",
    "#from dataset_loader import load_dataset\n",
    "\n",
    "#tf.enable_eager_execution()\n",
    "INPUT_WIDTH = 64\n",
    "INPUT_HEIGHT = 65\n",
    "\n",
    "INPUT_SIZE = 64\n",
    "\n",
    "INPUT_CHANNELS = 1\n",
    "\n",
    "NUM_CLASSES = 5\n",
    "\n",
    "LEARNING_RATE = 0.0005   # Original value: 0.01\n",
    "MOMENTUM = 0.9\n",
    "KEEP_PROB = 1\n",
    "\n",
    "EPOCHS = 10\n",
    "GLOBAL_STEPS = 5\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "NUM_PARRALLEL_THREADS = 8\n",
    "\n",
    "GRAYSCALE=True\n",
    "IS_FREQUENCY = True\n",
    "\n",
    "\n",
    "train_sub_dir = '/data/small_dataset/image_format_small_dataset/*/*'\n",
    "val_sub_dir = '/data/small_dataset/image_format_small_dataset_val/*/*'\n",
    "test_sub_dir = '/data/small_dataset/image_format_small_dataset_test/*/*'\n",
    "\n",
    "frequency_train_sub_dir = '/data/cogisen_frequency_data/image_format_small_dataset_cogisen_updated/*/*/*.csv'\n",
    "frequency_val_sub_dir = '/data/cogisen_frequency_data/image_format_small_dataset_val_cogisen_updated/*/*/*.csv'\n",
    "frequency_test_sub_dir = '/data/cogisen_frequency_data/image_format_small_dataset_test_cogisen_updated/*/*/*.csv'\n",
    "\n",
    "\n",
    "home_dir = os.path.dirname(os.path.realpath('__file__'))\n",
    "\n",
    "train_dir = home_dir + train_sub_dir\n",
    "val_dir = home_dir + val_sub_dir\n",
    "test_dir = home_dir + test_sub_dir\n",
    "\n",
    "\n",
    "frequency_train_dir = home_dir + frequency_train_sub_dir\n",
    "frequency_val_dir = home_dir + frequency_val_sub_dir\n",
    "frequency_test_dir = home_dir + frequency_test_sub_dir\n",
    "\n",
    "\n",
    "\n",
    "training_dataset= load_dataset(img_dir= train_dir,frequency_dir=frequency_train_dir,minibatch_size=BATCH_SIZE,image_size=INPUT_SIZE,grayscale=GRAYSCALE,num_parallel_calls=NUM_PARRALLEL_THREADS,is_frequency=IS_FREQUENCY)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_no = 1\n",
    "\n",
    "\n",
    "\n",
    "# logdir = './log/simple_model/frequency_data/grayscale'+str(experiment_no)\n",
    "# weight_dir = './weights/simple_model/frequency_data/grayscale/'+str(experiment_no)+'/model'\n",
    "\n",
    "\n",
    "logdir = home_dir+'/log/test/' + str(test_no)\n",
    "\n",
    "weight_dir = home_dir+'/weights/test/' +str(test_no)\n",
    "\n",
    "weights = weight_dir +'/model'\n",
    "if not os.path.exists(weight_dir):\n",
    "    os.makedirs(os.path.join(weight_dir))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'XLA_GPU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/device:XLA_GPU:0']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-c8fd937ffc9a>:4: DatasetV1.output_types (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_types(dataset)`.\n",
      "WARNING:tensorflow:From <ipython-input-4-c8fd937ffc9a>:4: DatasetV1.output_shapes (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_shapes(dataset)`.\n",
      "WARNING:tensorflow:From /home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py:348: Iterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_types(iterator)`.\n",
      "WARNING:tensorflow:From /home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py:349: Iterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_shapes(iterator)`.\n",
      "WARNING:tensorflow:From /home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py:351: Iterator.output_classes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_classes(iterator)`.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "handle = tf.placeholder(tf.string, shape=[],name=\"data_handle\")\n",
    "\n",
    "with tf.name_scope('iterators'):\n",
    "    training_iterator = tf.data.Iterator.from_structure(training_dataset.output_types,training_dataset.output_shapes)\n",
    "    training_init_op = training_iterator.make_initializer(training_dataset)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = tf.data.Iterator.from_string_handle(\n",
    "    handle, training_iterator.output_types,training_dataset.output_shapes)\n",
    "\n",
    "next_training_element = iterator.get_next()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with tf.device('/device:XLA_GPU:0'):\n",
    "model = Simple_Model(next_training_element,input_height=INPUT_HEIGHT,input_width=INPUT_WIDTH, num_classes=NUM_CLASSES,input_channels=INPUT_CHANNELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:XLA_GPU:0'):\n",
    "\n",
    "    with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)) as sess:\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        file_writer = tf.summary.FileWriter(logdir=logdir, graph=sess.graph)\n",
    "\n",
    "        \n",
    "        summary_operation = tf.summary.merge_all()\n",
    "        \n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        for epoch in range(EPOCHS):\n",
    "            training_string_handle =  sess.run(training_iterator.string_handle())\n",
    "\n",
    "            sess.run(training_init_op,feed_dict={handle:training_string_handle})\n",
    "            while True:\n",
    "                try:\n",
    "                    _, accuracy,summary,predictions,Y= sess.run([model.training_operation,model.accuracy_operation,summary_operation,model.predictions,model.Y],feed_dict={handle:training_string_handle})\n",
    "                   \n",
    "                \n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    \n",
    "                    file_writer.add_summary(summary, epoch)                \n",
    "                    \n",
    "                    break\n",
    "                saver.save(sess, weights,global_step=GLOBAL_STEPS,write_meta_graph=True)\n",
    "            \n",
    "           \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_dir = weights+'-'+str(GLOBAL_STEPS)+'.meta'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "graph = tf.get_default_graph()\n",
    "saver = tf.train.import_meta_graph(meta_dir)\n",
    "\n",
    "val_dataset = load_dataset(img_dir= val_dir,frequency_dir=frequency_val_dir,minibatch_size=1500,image_size=INPUT_SIZE,grayscale=GRAYSCALE,num_parallel_calls=NUM_PARRALLEL_THREADS,is_frequency=IS_FREQUENCY)\n",
    "\n",
    "val_iterator = tf.data.Iterator.from_structure(val_dataset.output_types,val_dataset.output_shapes)\n",
    "val_init_op = val_iterator.make_initializer(val_dataset,name='val_init_op')\n",
    " \n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)) as sess:\n",
    "    \n",
    "    \n",
    "    print('validation dataset...')\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess, tf.train.latest_checkpoint(weight_dir))\n",
    "   \n",
    "    iterator_handle = graph.get_tensor_by_name('data_handle:0')\n",
    "    val_handle = sess.run(val_iterator.string_handle())\n",
    "    \n",
    "\n",
    "    \n",
    "    sess.run(val_init_op,feed_dict={iterator_handle:val_handle})\n",
    "\n",
    "    accuracy_op = graph.get_tensor_by_name('accuracy/accuracy_operation:0')\n",
    "   \n",
    "    while True:\n",
    "        try:\n",
    "            val_accuracy = sess.run([accuracy_op],feed_dict={iterator_handle:val_handle})\n",
    "\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"accuracy for validation set :  {0}\".format(val_accuracy))\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "graph = tf.get_default_graph()\n",
    "saver = tf.train.import_meta_graph(meta_dir)\n",
    "\n",
    "test_dataset = load_dataset(img_dir= test_dir,frequency_dir=frequency_test_dir,minibatch_size=1500,image_size=INPUT_SIZE,grayscale=GRAYSCALE,num_parallel_calls=NUM_PARRALLEL_THREADS,is_frequency=IS_FREQUENCY)\n",
    "\n",
    "test_iterator = tf.data.Iterator.from_structure(test_dataset.output_types,test_dataset.output_shapes)\n",
    "test_init_op = test_iterator.make_initializer(test_dataset,name='test_init_op')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "i =0 \n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)) as sess:\n",
    "    \n",
    "    \n",
    "    print('testing dataset...')\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess, tf.train.latest_checkpoint(weight_dir))\n",
    "   # val_op = graph.get_operation_by_name(\"iterators/val_init_op\")\n",
    "    iterator_handle = graph.get_tensor_by_name('data_handle:0')\n",
    "    test_handle = sess.run(test_iterator.string_handle())\n",
    "\n",
    "    \n",
    "    sess.run(test_init_op,feed_dict={iterator_handle:test_handle})\n",
    "\n",
    "    accuracy_op = graph.get_tensor_by_name('accuracy/accuracy_operation:0')\n",
    "   \n",
    "    while True:\n",
    "        try:\n",
    "            test_accuracy = sess.run([accuracy_op],feed_dict={iterator_handle:test_handle})\n",
    "\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"accuracy for testing set :  {0}\".format(test_accuracy))\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
