{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = ['electrons','protons','muons','pions','gamma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "  # convert the path to a list of path components and one hot them\n",
    "    parts = tf.string_split([file_path], '/')\n",
    "    label = parts.values[-2] \n",
    "    matches = tf.stack([tf.equal(label, s) for s in vocab], axis=-1)\n",
    "    onehot = tf.cast(matches, tf.float32)\n",
    "    return onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_csv(file_path):\n",
    "    parts = tf.string_split([file_path], '/')\n",
    "    label = parts.values[-3] \n",
    "    matches = tf.stack([tf.equal(label, s) for s in vocab], axis=-1)\n",
    "    onehot = tf.cast(matches, tf.float32)\n",
    "    return onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_img(img_dir,image_size,grayscale):\n",
    "    \n",
    "    img = tf.io.read_file(img_dir)\n",
    "    # convert the compressed string to a uint8 tensor\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    # resize the image to the desired size.\n",
    "    #img = tf.image.per_image_standardization(img)\n",
    "    img = scale_normalize(img)\n",
    "    \n",
    "    img = tf.image.resize(img, [image_size, image_size])\n",
    "    \n",
    "    if grayscale:\n",
    "        img = tf.image.rgb_to_grayscale(img)\n",
    "    \n",
    "    label = get_label(img_dir)\n",
    "    \n",
    " \n",
    "        \n",
    "    return img,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_normalize(tensor):\n",
    "    tensor = tf.div(\n",
    "   tf.subtract(\n",
    "      tensor, \n",
    "      tf.reduce_min(tensor)\n",
    "   ), \n",
    "   tf.subtract(\n",
    "      tf.reduce_max(tensor), \n",
    "      tf.reduce_min(tensor)\n",
    "   )\n",
    ")\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_csv(features):\n",
    "    features =  tf.stack(list(features.values()), axis=-1)\n",
    "    features = tf.reshape(features,shape=[-1,1])\n",
    "    #features = tf.image.per_image_standardization(features)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_csv(frequency_dir):\n",
    "    csv_dataset = tf.data.experimental.make_csv_dataset(frequency_dir,batch_size=8,shuffle=False)\n",
    "    csv_dataset = csv_dataset.map(process_csv,num_parallel_calls=8)\n",
    "    return csv_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_frequency_data_to_image(image_with_label,frequency_data,grayscale):\n",
    "    #frequency data is just a single 64 element row with shape [64,1]\n",
    "     img = image_with_label[0] \n",
    "     label = image_with_label[1]\n",
    "\n",
    "        \n",
    "     if grayscale:\n",
    "        #img has 1 channels with shape [img_size,img_size,1]\n",
    "        frequency_data = tf.expand_dims(frequency_data,axis=0) #new_shape:[1,64,1]\n",
    "        combined_data_point = tf.concat([img,frequency_data],0) #final_shape:[65,64,1]\n",
    "\n",
    "        \n",
    "            \n",
    "     else:      \n",
    "        #img has 3 channels with shape [img_size,img_size,1]\n",
    "         frequency_data = tf.tile(frequency_data,[1,3]) #new_shape:[64,3]\n",
    "         frequency_data = tf.expand_dims(frequency_data,axis=0) #new_shape:[1,64,3]        \n",
    "         combined_data_point = tf.concat([img,frequency_data],0) #final_shape:[65,64,3]\n",
    "\n",
    "\n",
    "        \n",
    "     return combined_data_point,label    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(img_dir,image_size,num_parallel_calls,grayscale):\n",
    "    list_images = tf.data.Dataset.list_files(img_dir)\n",
    "    img_dataset = list_images.map(lambda img_dir: extract_img(img_dir,image_size,grayscale), num_parallel_calls=num_parallel_calls)\n",
    "    return img_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_csv_and_img(img_dir,frequency_dir,image_size,minibatch_size,grayscale,num_parallel_calls):\n",
    "    \n",
    "#     list_images = tf.data.Dataset.list_files(img_dir)\n",
    "#     img_dataset = list_images.map(lambda img_dir: extract_img(img_dir,image_size), num_parallel_calls=num_parallel_calls)\n",
    "    img_dataset = load_images(img_dir,image_size=image_size,num_parallel_calls=num_parallel_calls,grayscale=grayscale)\n",
    "    \n",
    "    \n",
    "    csv_dataset = extract_csv(frequency_dir)\n",
    "    \n",
    "    combined_dataset = tf.data.Dataset.zip((img_dataset, csv_dataset))\n",
    "    \n",
    "    \n",
    "    \n",
    "    combined_dataset = combined_dataset.map(lambda image_with_label,frequency_data:add_frequency_data_to_image(image_with_label,frequency_data,grayscale),num_parallel_calls=num_parallel_calls)\n",
    "    \n",
    "    return combined_dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(img_dir,frequency_dir,minibatch_size,image_size,num_parallel_calls=8,grayscale=False,is_frequency=True):\n",
    "    \n",
    "    if is_frequency:\n",
    "        dataset = combine_csv_and_img(img_dir,frequency_dir,image_size,minibatch_size,grayscale,num_parallel_calls=num_parallel_calls).batch(minibatch_size).prefetch(1) \n",
    "    #batched_dataset = dataset.batch(minibatch_size).prefetch(1)\n",
    "    else:\n",
    "        dataset = load_images(img_dir,image_size=image_size,num_parallel_calls=num_parallel_calls,grayscale=grayscale).batch(minibatch_size).prefetch(1)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
