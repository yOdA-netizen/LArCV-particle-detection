{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/shubham/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = ['electrons','protons','muons','pions','gamma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "  # convert the path to a list of path components and one hot them\n",
    "    parts = tf.string_split([file_path], '/')\n",
    "    label = parts.values[-2] \n",
    "    matches = tf.stack([tf.equal(label, s) for s in vocab], axis=-1)\n",
    "    onehot = tf.cast(matches, tf.float32)\n",
    "    return onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_csv(file_path):\n",
    "    parts = tf.string_split([file_path], '/')\n",
    "    label = parts.values[-3] \n",
    "    matches = tf.stack([tf.equal(label, s) for s in vocab], axis=-1)\n",
    "    onehot = tf.cast(matches, tf.float32)\n",
    "    return onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_img(img_dir,image_size,grayscale):\n",
    "    \n",
    "    img = tf.io.read_file(img_dir)\n",
    "    # convert the compressed string to a uint8 tensor\n",
    "    img = tf.image.decode_png(img, channels=3)\n",
    "\n",
    "    img = tf.dtypes.cast(img,dtype=tf.float32)\n",
    "    \n",
    "    # resize the image to the desired size.\n",
    "    \n",
    "    \n",
    "        \n",
    "    img = tf.image.resize(img, [image_size, image_size])\n",
    "    \n",
    "    if grayscale:\n",
    "        img = tf.image.rgb_to_grayscale(img)\n",
    "        \n",
    "    #img = scale_normalize(img)\n",
    "    img = tf.image.per_image_standardization(img)\n",
    "    \n",
    "    label = get_label(img_dir)\n",
    "    \n",
    " \n",
    "        \n",
    "    return img,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_normalize(tensor):\n",
    "#     tensor = tf.div(\n",
    "#    tf.subtract(\n",
    "#       tensor, \n",
    "#       tf.reduce_min(tensor)\n",
    "#    ), \n",
    "#    tf.subtract(\n",
    "#       tf.reduce_max(tensor), \n",
    "#       tf.reduce_min(tensor)\n",
    "#    )\n",
    "# )\n",
    "\n",
    "    tensor = tensor/255.0\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(features):\n",
    "    features = tf.math.divide(\n",
    "        tf.math.subtract(features,\n",
    "                         tf.math.reduce_mean(features,axis=0)),\n",
    "        tf.math.reduce_std(features,axis=0))\n",
    "    return features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_csv(features):\n",
    "    features =  tf.stack(list(features.values()), axis=-1)\n",
    "    features = tf.reshape(features,shape=[-1,1])\n",
    "    #features = tf.image.per_image_standardization(features)\n",
    "    features = normalize(features)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_csv(frequency_dir):\n",
    "    csv_dataset = tf.data.experimental.make_csv_dataset(frequency_dir,batch_size=8,shuffle=False)\n",
    "    csv_dataset = csv_dataset.map(process_csv,num_parallel_calls=8)\n",
    "    return csv_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_frequency_data_to_image(image_with_label,frequency_data,grayscale):\n",
    "    #frequency data is just a single 64 element row with shape [64,1]\n",
    "     img = image_with_label[0] \n",
    "     label = image_with_label[1]\n",
    "\n",
    "        \n",
    "     if grayscale:\n",
    "        #img has 1 channels with shape [img_size,img_size,1]\n",
    "        frequency_data = tf.expand_dims(frequency_data,axis=0) #new_shape:[1,64,1]\n",
    "        combined_data_point = tf.concat([img,frequency_data],0) #final_shape:[65,64,1]\n",
    "        \n",
    "        \n",
    "            \n",
    "     else:      \n",
    "        #img has 3 channels with shape [img_size,img_size,1]\n",
    "         frequency_data = tf.tile(frequency_data,[1,3]) #new_shape:[64,3]\n",
    "         frequency_data = tf.expand_dims(frequency_data,axis=0) #new_shape:[1,64,3]        \n",
    "         combined_data_point = tf.concat([img,frequency_data],0) #final_shape:[65,64,3]\n",
    "         \n",
    "\n",
    "     #combined_data_point = tf.image.per_image_standardization(combined_data_point) #standard normalize the combined data\n",
    "        \n",
    "     return combined_data_point,label    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(img_dir,image_size,num_parallel_calls,grayscale):\n",
    "    list_images = tf.data.Dataset.list_files(img_dir)\n",
    "    img_dataset = list_images.map(lambda img_dir: extract_img(img_dir,image_size,grayscale), num_parallel_calls=num_parallel_calls)\n",
    "    return img_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_csv_and_img(img_dir,frequency_dir,image_size,minibatch_size,grayscale,num_parallel_calls):\n",
    "    \n",
    "#     list_images = tf.data.Dataset.list_files(img_dir)\n",
    "#     img_dataset = list_images.map(lambda img_dir: extract_img(img_dir,image_size), num_parallel_calls=num_parallel_calls)\n",
    "    img_dataset = load_images(img_dir,image_size=image_size,num_parallel_calls=num_parallel_calls,grayscale=grayscale)\n",
    "    \n",
    "    \n",
    "    csv_dataset = extract_csv(frequency_dir)\n",
    "    \n",
    "    combined_dataset = tf.data.Dataset.zip((img_dataset, csv_dataset))\n",
    "    \n",
    "    \n",
    "    \n",
    "    combined_dataset = combined_dataset.map(lambda image_with_label,frequency_data:add_frequency_data_to_image(image_with_label,frequency_data,grayscale),num_parallel_calls=num_parallel_calls)\n",
    "    \n",
    "    return combined_dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(img_dir,frequency_dir,minibatch_size,image_size,num_parallel_calls=8,grayscale=False,is_frequency=True):\n",
    "    \n",
    "    if is_frequency:\n",
    "        dataset = combine_csv_and_img(img_dir,frequency_dir,image_size,minibatch_size,grayscale,num_parallel_calls=num_parallel_calls).batch(minibatch_size).prefetch(1) \n",
    "    #batched_dataset = dataset.batch(minibatch_size).prefetch(1)\n",
    "    else:\n",
    "        dataset = load_images(img_dir,image_size=image_size,num_parallel_calls=num_parallel_calls,grayscale=grayscale).batch(minibatch_size).prefetch(3)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
